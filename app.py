import streamlit as st
import os
from dotenv import load_dotenv
import requests
import time
import pandas as pd

from googleapiclient.discovery import build
from youtube_transcript_api import YouTubeTranscriptApi

from openai import OpenAI

import psycopg2
from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT

from extract_blog_content import blog_content


st.set_page_config(page_title="ìœ íŠœë¸Œ ì±„ë„ ë¶„ì„ê¸°", layout="wide")

load_dotenv()

YOUTUBE_API_KEY = os.getenv('YOUTUBE_API_KEY')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

openai_client = OpenAI(api_key=OPENAI_API_KEY)


# ìœ íŠœë¸Œ ì‡¼ì¸ ì¸ì§€ ì•„ë‹Œì§€ êµ¬ë¶„
def is_youtubeshorts(video_id):
    url = 'https://www.youtube.com/shorts/' + video_id
    req = requests.head(url)
    
    return req.status_code == 200

# YouTube Transcript APIë¡œ ìŠ¤í¬ë¦½íŠ¸ ìš”ì•½
def youtube_transcript(video_id, max_retries=3, retry_delay=1.5):
    """
    YouTube ë™ì˜ìƒì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜.
    max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
    retry_delay: ì¬ì‹œë„ ì‚¬ì´ì˜ ëŒ€ê¸° ì‹œê°„(ì´ˆ)
    """
    for retry in range(max_retries):
        try:
            if retry > 0:
                print(f"ìë§‰ ì¶”ì¶œ ì¬ì‹œë„ ì¤‘... ({retry}/{max_retries-1})")
                time.sleep(retry_delay)  # ì¬ì‹œë„ ì‚¬ì´ì— ëŒ€ê¸° ì‹œê°„ ì¶”ê°€
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ìë§‰ ëª©ë¡ í™•ì¸
            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
            
            # ë””ë²„ê¹…ì„ ìœ„í•´ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ìë§‰ ì¶œë ¥
            print(f"\nì˜ìƒ ID {video_id}ì˜ ì‚¬ìš© ê°€ëŠ¥í•œ ìë§‰ ëª©ë¡:")
            for transcript in transcript_list:
                print(f"- {transcript.language} ({transcript.language_code}): {'ìë™ ìƒì„±' if transcript.is_generated else 'ìˆ˜ë™ ìƒì„±'}")
            
            transcript = None
            
            # ìˆœì°¨ì ìœ¼ë¡œ ìë§‰ ì‹œë„
            try:
                # 1. ìˆ˜ë™ í•œêµ­ì–´ ìë§‰
                transcript = transcript_list.find_manually_created_transcript(['ko'])
                print('ìˆ˜ë™ ìƒì„± í•œêµ­ì–´ ìë§‰ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.')
            except Exception as e1:
                try:
                    # 2. ìë™ ìƒì„± í•œêµ­ì–´ ìë§‰
                    transcript = transcript_list.find_generated_transcript(['ko'])
                    print('ìë™ ìƒì„± í•œêµ­ì–´ ìë§‰ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.')
                except Exception as e2:
                    try:
                        # 3. ë‹¤ë¥¸ í˜•ì‹ì˜ í•œêµ­ì–´ ìë§‰
                        for t in transcript_list:
                            if t.language_code.startswith('ko'):
                                transcript = t
                                print(f'í•œêµ­ì–´ ìë§‰ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤: {t.language_code} ({"ìë™ ìƒì„±" if t.is_generated else "ìˆ˜ë™ ìƒì„±"})')
                                break
                    except Exception as e3:
                        print('í•œêµ­ì–´ ìë§‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
                        # ê³„ì† ì§„í–‰í•˜ì—¬ ë‹¤ë¥¸ ì‹œë„ë¥¼ í•´ë³´ê¸° ìœ„í•´ continue í•˜ì§€ ì•ŠìŒ
            
            if transcript:
                try:
                    # ìë§‰ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    transcript_data = transcript.fetch()
                    first_minute = []
                    current_time = 0
                    
                    for line in transcript_data:
                        if current_time > 180:  # 180ì´ˆ = 3ë¶„
                            break
                        first_minute.append(line['text'])
                        current_time += line['duration']
                    
                    result = ' '.join(first_minute)
                    if result:
                        print(f'ì„±ê³µì ìœ¼ë¡œ {current_time:.1f}ì´ˆ ë¶„ëŸ‰ì˜ ìë§‰ì„ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.')
                        return result
                    else:
                        print('ìë§‰ì€ ì°¾ì•˜ìœ¼ë‚˜ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.')
                except Exception as e:
                    print(f'ìë§‰ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}')
            else:
                print('ì‚¬ìš© ê°€ëŠ¥í•œ ìë§‰ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')
                
        except Exception as e:
            print(f'ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}')
        
        # ì¬ì‹œë„ê°€ ë‚¨ì•„ ìˆìœ¼ë©´ ê³„ì† ì‹œë„
        if retry < max_retries - 1:
            continue
    
    # ëª¨ë“  ì‹œë„ê°€ ì‹¤íŒ¨í•˜ë©´ ëª…í™•í•œ ë©”ì‹œì§€ ë°˜í™˜
    return "âš ï¸ ìë§‰ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ì—¬ëŸ¬ ë²ˆ ì‹œë„í–ˆìœ¼ë‚˜ ì‹¤íŒ¨)"

# ë§Œ ë‹¨ìœ„ë¡œ ë³€í™˜
def format_to_10k(n):
    num = round(n / 10000, 1)  # ì†Œìˆ˜ì  ì²«ì§¸ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼
    return f"{num}ë§Œ"


# PostgreSQLì— ì ‘ì†
def connect_postgres():
    conn = psycopg2.connect(
        host="15.164.112.237", 
        database="dify", 
        user="difyuser", 
        password="bico0218"
    )
    conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
    
    return conn

def search_unique_id():
    conn = connect_postgres()
    cur = conn.cursor()
    
    # ì‹œí€€ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒì„±
    cur.execute("CREATE SEQUENCE IF NOT EXISTS youtube_search_seq")
    
    # ë‹¤ìŒ ì‹œí€€ìŠ¤ ê°’ ê°€ì ¸ì˜¤ê¸°
    cur.execute("SELECT nextval('youtube_search_seq')")
    search_id = cur.fetchone()[0]
    
    cur.close()
    conn.close()
    
    return search_id

# ì±„ë„ ì •ë³´ ì €ì¥
def save_info(table_name, search_unique_id, keyword, channel_url, channel_name, channel_subscribers, 
                      video_id, video_title, video_thumbnail, video_view_count, video_like_count, video_comment_count, video_view_subscriber_ratio, 
                      is_shorts, transcript, published_at, top_comments):
    conn = connect_postgres()
    cur = conn.cursor()
    
    # ëŒ“ê¸€ ì •ë³´ ì¤€ë¹„ (ê° ëŒ“ê¸€ì„ ë³„ë„ ë³€ìˆ˜ë¡œ)
    comment_1 = ""
    comment_2 = ""
    comment_3 = ""
    
    # ëŒ“ê¸€ ì •ë³´ ì¤€ë¹„ (ë‚´ìš©ë§Œ ì €ì¥)
    comment_1 = comments[0]['text'] if len(comments) > 0 else "ë‚´ìš© ì—†ìŒ"
    comment_2 = comments[1]['text'] if len(comments) > 1 else "ë‚´ìš© ì—†ìŒ"
    comment_3 = comments[2]['text'] if len(comments) > 2 else "ë‚´ìš© ì—†ìŒ"
    
    cur.execute(f"""
    INSERT INTO {table_name} (
        search_unique_id, keyword, channel_url, channel_name, channel_subscribers, 
        video_id, video_title, video_thumbnail, video_view_count, video_like_count, video_comment_count, video_view_subscriber_ratio, 
        is_shorts, transcript, published_at, comment_1, comment_2, comment_3)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """, 
        (search_unique_id, keyword, channel_url, channel_name, channel_subscribers, 
         video_id, video_title, video_thumbnail, video_view_count, video_like_count, video_comment_count, video_view_subscriber_ratio, 
         is_shorts, transcript, published_at, comment_1, comment_2, comment_3)
    )
    
    conn.commit()
    cur.close()
    conn.close()

# ìœ íŠœë¸Œ ì±„ë„ ë°ì´í„° ìˆ˜ì§‘
class YouTubeAnalyzer:
    def __init__(self, api_key):
        self.youtube = build('youtube', 'v3', developerKey=api_key)
    
    # Extract channel ID from URL or custom URL
    def get_channel_id(self, channel_url):
        if 'youtube.com/channel/' in channel_url:
            return channel_url.split('channel/')[1].split('/')[0]
        elif 'youtube.com/@' in channel_url:
            username = channel_url.split('@')[1].split('/')[0]
            request = self.youtube.channels().list(
                part='id',
                forUsername=username
            )
            try:
                response = request.execute()
                if response.get('items'):
                    return response['items'][0]['id']
            except:
                pass
            
            # If the above method fails, try with search
            request = self.youtube.search().list(
                part='snippet',
                q=username,
                type='channel',
                maxResults=1
            )
            response = request.execute()
            
            # Verify the channel handle matches
            for item in response['items']:
                channel_id = item['snippet']['channelId']
                channel_info = self.youtube.channels().list(
                    part='snippet',
                    id=channel_id
                ).execute()
                
                if channel_info['items'][0]['snippet'].get('customUrl', '').lower() == f'@{username.lower()}':
                    return channel_id
            
            raise ValueError(f"Could not find channel ID for {channel_url}")
    
    # Get channel statistics including subscriber count
    def get_channel_stats(self, channel_id):
        request = self.youtube.channels().list(
            part='statistics,snippet',
            id=channel_id
        )
        response = request.execute()
        channel_info = response['items'][0]
        return {
            'title': channel_info['snippet']['title'],
            'subscribers': int(channel_info['statistics']['subscriberCount']),
            'thumbnail': channel_info['snippet']['thumbnails']['high']['url']
        }
    
    # í•´ë‹¹ ì±„ë„ì˜ ë™ì˜ìƒ ì •ë³´
    def get_all_videos(self, channel_id):
        videos = []
        next_page_token = None
        
        while True:
            request = self.youtube.search().list(
                part='snippet',
                channelId=channel_id,
                maxResults=50,
                type='video',
                pageToken=next_page_token,
                order='date'  # ìµœì‹  ì˜ìƒë¶€í„°
            )
            response = request.execute()
            
            # Get video IDs for batch statistics request
            video_ids = [item['id']['videoId'] for item in response['items']]
            
            if not video_ids:
                break
            
            # Get video statistics in batch
            stats_request = self.youtube.videos().list(
                part='statistics',
                id=','.join(video_ids)
            )
            stats_response = stats_request.execute()
            
            # Combine video information with statistics
            for video, stats in zip(response['items'], stats_response['items']):
                videos.append({
                    'title': video['snippet']['title'],
                    'thumbnail': video['snippet']['thumbnails']['high']['url'],
                    'views': int(stats['statistics'].get('viewCount', 0)),
                    'like_count': int(stats['statistics'].get('likeCount', 0)),
                    'comment_count': int(stats['statistics'].get('commentCount', 0)),
                    'published_at': video['snippet']['publishedAt'],
                    'video_id': video['id']['videoId']
                })
            
            next_page_token = response.get('nextPageToken')
            if not next_page_token:
                break
        
        return videos
    
    # ìƒìœ„ nê°œ ëŒ“ê¸€
    def get_top_comments(self, video_id, max_results=3):
        """Get top comments for a specific video"""
        try:
            request = self.youtube.commentThreads().list(
                part='snippet',
                videoId=video_id,
                maxResults=max_results,
                order='relevance'  # ì¸ê¸°ìˆœ ì •ë ¬
            )
            response = request.execute()
            
            comments = []
            for item in response.get('items', []):
                comment = item['snippet']['topLevelComment']['snippet']
                comments.append({
                    'author': comment['authorDisplayName'],
                    'text': comment['textDisplay'],
                    'like_count': comment['likeCount'],
                    'published_at': comment['publishedAt']
                })
            
            return comments
        except Exception as e:
            # ëŒ“ê¸€ì´ ë¹„í™œì„±í™”ëœ ê²½ìš° ë“±ì˜ ì˜ˆì™¸ ì²˜ë¦¬
            return [{'author': 'ëŒ“ê¸€ ì—†ìŒ', 'text': 'ëŒ“ê¸€ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ë¹„í™œì„±í™”ë˜ì—ˆê±°ë‚˜ ì ‘ê·¼ ë¶ˆê°€)', 'like_count': 0, 'published_at': ''}]


# ì±„ë„ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
def get_info(search_id, table_name):  # channel_info
    conn = connect_postgres()
    cur = conn.cursor()

    cur.execute(f"""
    SELECT 
        channel_name, video_id, video_title, video_thumbnail, video_view_count, video_like_count, video_comment_count, video_view_subscriber_ratio, is_shorts, comment_1, comment_2, comment_3, transcript
    FROM 
        {table_name} 
    WHERE 
        search_unique_id = %s
    """, (search_id,))

    results = cur.fetchall()

    # í‚¤ì›Œë“œë„ ì¡°íšŒí•´ì•¼
    columns = [
        'ì±„ë„ëª…', 'video_id', 'ì œëª©', 'ì¸ë„¤ì¼', 'ì¡°íšŒìˆ˜', 'ì¢‹ì•„ìš”', 'ëŒ“ê¸€ìˆ˜', 
        'ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨', 'ì‡¼ì¸ ', 'ëŒ“ê¸€1', 'ëŒ“ê¸€2', 'ëŒ“ê¸€3', 'ìŠ¤í¬ë¦½íŠ¸'
    ]
    
    df = pd.DataFrame(results, columns=columns)
    
    cur.close()
    conn.close()
    
    return df

# í‚¤ì›Œë“œë¡œ ë™ì˜ìƒ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
def fetch_youtube_data(search_query, max_results=50):
    youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)
    
    videos_data = []
    request = youtube.search().list(
        q=search_query,
        part='snippet',
        type='video',
        maxResults=min(50, max_results)
    )
    
    response = request.execute()
    video_ids = [item['id']['videoId'] for item in response['items']]
    stats_request = youtube.videos().list(
        part='statistics',
        id=','.join(video_ids)
    )
    stats_response = stats_request.execute()
    channel_ids = [item['snippet']['channelId'] for item in response['items']]
    channels_request = youtube.channels().list(
        part='statistics',
        id=','.join(set(channel_ids))
    )
    channels_response = channels_request.execute()
    
    channel_subscribers = {
        channel['id']: int(channel['statistics'].get('subscriberCount', 0))
        for channel in channels_response['items']
    }
    
    for video, stats in zip(response['items'], stats_response['items']):
        views = int(stats['statistics'].get('viewCount', 0))
        if views >= 1000:
            video_id = video['id']['videoId']
            channel_id = video['snippet']['channelId']
            subscriber_count = channel_subscribers.get(channel_id, 0)
            view_sub_ratio = (views / subscriber_count) * 100 if subscriber_count > 0 else 0
            script = youtube_transcript(video_id)
            is_shorts = is_youtubeshorts(video_id)
            videos_data.append({
                'title': video['snippet']['title'], 
                'channel': video['snippet']['channelTitle'], 
                'publishedAt': video['snippet']['publishedAt'], 
                'views': views, 
                'subscribers': subscriber_count, 
                'view_sub_ratio': round(view_sub_ratio, 2),
                'likes': int(stats['statistics'].get('likeCount', 0)), 
                'comments': int(stats['statistics'].get('commentCount', 0)), 
                'description': video['snippet']['description'], 
                'url': f"https://www.youtube.com/watch?v={video_id}", 
                'thumbnail': video['snippet']['thumbnails']['high']['url'], 
                '1min_script': script,
                'is_shorts': is_shorts
            })
    
    return pd.DataFrame(videos_data)

# # ì±„ë„ ë™ì˜ìƒ ë¶„ì„ # #
# ì˜ìƒ ë°ì´í„° ë¶„ì„ í•¨ìˆ˜
def analyze_video_data(client, videos_data, is_shorts=False):
    """
    Parameters:
    client (OpenAI): OpenAI í´ë¼ì´ì–¸íŠ¸
    videos_data (DataFrame): ë¶„ì„í•  ì˜ìƒ ë°ì´í„°
    is_shorts (bool): ì‡¼ì¸  ì˜ìƒ ë¶„ì„ ì—¬ë¶€ (True: ì‡¼ì¸ , False: ë¡±í¼)
    
    Returns:
    str: ë¶„ì„ ê²°ê³¼
    """
    # í•´ë‹¹ ì¹´í…Œê³ ë¦¬(ì‡¼ì¸ /ë¡±í¼)ì— ë§ëŠ” ì˜ìƒ í•„í„°ë§
    if is_shorts:
        filtered_data = videos_data[videos_data['ì‡¼ì¸ '] == True]
        content_type = "ì‡¼ì¸ (Shorts)"
    else:
        filtered_data = videos_data[videos_data['ì‡¼ì¸ '] == False]
        content_type = "ë¡±í¼(Longform)"
    
    # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
    if filtered_data.empty:
        return f"ë¶„ì„í•  {content_type} ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤."
    
    # ë°ì´í„° ì¤€ë¹„
    data_summary = {
        "ì˜ìƒ_ìˆ˜": len(filtered_data),
        "í‰ê· _ì¡°íšŒìˆ˜": filtered_data['ì¡°íšŒìˆ˜'].mean(),
        "í‰ê· _ì¢‹ì•„ìš”": filtered_data['ì¢‹ì•„ìš”'].mean(),
        "í‰ê· _ëŒ“ê¸€ìˆ˜": filtered_data['ëŒ“ê¸€ìˆ˜'].mean(),
        "í‰ê· _ì¡°íšŒêµ¬ë…ë¹„ìœ¨": filtered_data['ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨'].mean(),
        "ìµœê³ _ì¡°íšŒìˆ˜": filtered_data['ì¡°íšŒìˆ˜'].max(),
        "ìµœê³ _ì¢‹ì•„ìš”": filtered_data['ì¢‹ì•„ìš”'].max(),
        "ìµœê³ _ëŒ“ê¸€ìˆ˜": filtered_data['ëŒ“ê¸€ìˆ˜'].max()
    }
    
    # ìƒìœ„ 3ê°œ ì˜ìƒ ì •ë³´ (ì¡°íšŒìˆ˜ ê¸°ì¤€)
    top_videos = filtered_data.sort_values(by='ì¡°íšŒìˆ˜', ascending=False).head(3)
    top_videos_info = []
    
    for _, row in top_videos.iterrows():
        video_info = {
            "ì œëª©": row['ì œëª©'],
            "ì¡°íšŒìˆ˜": row['ì¡°íšŒìˆ˜'],
            "ì¢‹ì•„ìš”": row['ì¢‹ì•„ìš”'],
            "ëŒ“ê¸€ìˆ˜": row['ëŒ“ê¸€ìˆ˜'],
            "ì¡°íšŒêµ¬ë…ë¹„ìœ¨": row['ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨']
        }
        top_videos_info.append(video_info)
    
    # í”„ë¡¬í”„íŠ¸ ì‘ì„±
    channel_name = filtered_data['ì±„ë„ëª…'].iloc[0]
    
    prompt = f"""
    ë‹¤ìŒì€ YouTube ì±„ë„ "{channel_name}"ì˜ {content_type} ì˜ìƒ {len(filtered_data)}ê°œì— ëŒ€í•œ ë°ì´í„°ì…ë‹ˆë‹¤:
    
    ì „ì²´ ë°ì´í„° ìš”ì•½:
    - ì˜ìƒ ìˆ˜: {data_summary['ì˜ìƒ_ìˆ˜']}ê°œ
    - í‰ê·  ì¡°íšŒìˆ˜: {data_summary['í‰ê· _ì¡°íšŒìˆ˜']:.1f}íšŒ
    - í‰ê·  ì¢‹ì•„ìš”: {data_summary['í‰ê· _ì¢‹ì•„ìš”']:.1f}ê°œ
    - í‰ê·  ëŒ“ê¸€ ìˆ˜: {data_summary['í‰ê· _ëŒ“ê¸€ìˆ˜']:.1f}ê°œ
    - í‰ê·  ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨: {data_summary['í‰ê· _ì¡°íšŒêµ¬ë…ë¹„ìœ¨']:.4f}
    
    ìƒìœ„ 3ê°œ ì˜ìƒ (ì¡°íšŒìˆ˜ ê¸°ì¤€):
    """
    
    for i, video in enumerate(top_videos_info):
        prompt += f"""
    {i+1}. "{video['ì œëª©']}"
       - ì¡°íšŒìˆ˜: {video['ì¡°íšŒìˆ˜']}íšŒ
       - ì¢‹ì•„ìš”: {video['ì¢‹ì•„ìš”']}ê°œ
       - ëŒ“ê¸€ ìˆ˜: {video['ëŒ“ê¸€ìˆ˜']}ê°œ
       - ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨: {video['ì¡°íšŒêµ¬ë…ë¹„ìœ¨']:.4f}
        """
    
    prompt += f"""
    ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë‚´ìš©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
    1. ì¡°íšŒìˆ˜, ì¢‹ì•„ìš”, ëŒ“ê¸€ ìˆ˜ì˜ ì „ë°˜ì ì¸ íŠ¸ë Œë“œì™€ ìƒê´€ê´€ê³„
    2. ê°€ì¥ ì¸ê¸° ìˆëŠ” ì˜ìƒë“¤ì˜ ê³µí†µì  (ì œëª© íŒ¨í„´, ì‹œì²­ì ì°¸ì—¬ë„ ë“±)
    3. ì‹œì²­ì ì°¸ì—¬ë„ê°€ ë†’ì€ ì˜ìƒì˜ íŠ¹ì§• (ì¢‹ì•„ìš”/ì¡°íšŒìˆ˜ ë¹„ìœ¨, ëŒ“ê¸€/ì¡°íšŒìˆ˜ ë¹„ìœ¨ ë“±)
    4. ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨ì„ í†µí•´ ë³¸ ì˜ìƒì˜ ì¸ê¸°ë„ ë¶„ì„
    5. {content_type} ì˜ìƒì˜ ì„±ê³µ ìš”ì¸ê³¼ ê°œì„ ì  ì œì•ˆ
    
    ë¶„ì„ ê²°ê³¼ëŠ” 400-500ë‹¨ì–´ ë‚´ì™¸ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o-2024-08-06",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ìœ íŠœë¸Œ ì±„ë„ê³¼ ì˜ìƒ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ê¹Šì´ ìˆê²Œ ë¶„ì„í•˜ê³  í†µì°°ë ¥ ìˆëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=1000
        )
        
        # ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        return response.choices[0].message.content.strip()
        
    except Exception as e:
        return f"ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ë¶„ì„ ê²°ê³¼ ì €ì¥ í•¨ìˆ˜
def save_video_analysis(search_unique_id, video_id, video_title, is_shorts, analysis_result):
    conn = connect_postgres()
    cur = conn.cursor()
    
    cur.execute("""
        INSERT INTO channel_analysis (search_unique_id, video_id, video_title, is_shorts, llm_analysis) VALUES (%s, %s, %s, %s, %s)
        """, 
        (search_unique_id, video_id, video_title, is_shorts, analysis_result)
    )
    
    conn.commit()
    cur.close()
    conn.close()

# ê° search_unique_idë³„ë¡œ ê°€ì¥ ë†’ì€ ë¹„ìœ¨ì˜ ë™ì˜ìƒ í•˜ë‚˜ì”© ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_top_videos_by_search_id(table_name):
    conn = connect_postgres()
    cur = conn.cursor()

    # ëª¨ë“  ê³ ìœ  search_unique_id ê°€ì ¸ì˜¤ê¸°
    cur.execute(f"SELECT DISTINCT search_unique_id FROM {table_name} ORDER BY search_unique_id DESC")
    search_ids = [row[0] for row in cur.fetchall()]
    
    # ê²°ê³¼ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    results = []
    
    # ê° search_unique_idì— ëŒ€í•´ ê°€ì¥ ë†’ì€ video_view_subscriber_ratioë¥¼ ê°€ì§„ ë™ì˜ìƒ ê°€ì ¸ì˜¤ê¸°
    for search_id in search_ids:
        cur.execute(f"""
        SELECT 
            search_unique_id, keyword, channel_name, video_id, video_title, video_thumbnail, 
            video_view_count, video_like_count, video_comment_count, video_view_subscriber_ratio, 
            is_shorts, comment_1, comment_2, comment_3, transcript
        FROM 
            {table_name} 
        WHERE 
            search_unique_id = %s
        ORDER BY 
            video_view_subscriber_ratio DESC
        LIMIT 1
        """, (search_id,))
        
        row = cur.fetchone()
        if row:
            results.append(row)
    
    # ì»¬ëŸ¼ ì´ë¦„
    columns = [
        'pk_ID', 'í‚¤ì›Œë“œ', 'ì±„ë„ëª…', 'video_id', 'ì œëª©', 'ì¸ë„¤ì¼', 
        'ì¡°íšŒìˆ˜', 'ì¢‹ì•„ìš”', 'ëŒ“ê¸€ìˆ˜', 'ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨', 
        'ì‡¼ì¸ ', 'ëŒ“ê¸€1', 'ëŒ“ê¸€2', 'ëŒ“ê¸€3', 'ìŠ¤í¬ë¦½íŠ¸'
    ]
    
    df = pd.DataFrame(results, columns=columns)
    
    cur.close()
    conn.close()
    
    return df

def blog_summarizer(client, text):
    try:
        # ì…ë ¥ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ ê²½ìš° ì œí•œ (API ì œí•œì„ ê³ ë ¤)
        if len(text) > 15000:
            text = text[:15000] + "..."
    
        summary = client.chat.completions.create(
            model='gpt-4o-2024-08-06', 
            messages=[
                {"role": "system", "content": "ë‹¤ìŒ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”. í•µì‹¬ ë‚´ìš©ê³¼ ì£¼ìš” í¬ì¸íŠ¸ë¥¼ í¬í•¨ì‹œì¼œì•¼ í•©ë‹ˆë‹¤."},
                {"role": "user", "content": text}
            ],
            temperature=0.3, 
            max_tokens=500,
        )
        
        return summary.choices[0].message.content.strip()
    
    except Exception as e:
        return {"ë¸”ë¡œê·¸ ë‚´ìš© ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.": str(e)}


st.title("ìœ íŠœë¸Œ ì±„ë„ ë¶„ì„ê¸°")
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["ì±„ë„ ë°ì´í„° ìˆ˜ì§‘", "í‚¤ì›Œë“œ ê¸°ë°˜ ë°ì´í„° ìˆ˜ì§‘", "ì±„ë„ ë°ì´í„° ì¡°íšŒ", "í‚¤ì›Œë“œ ë°ì´í„° ì¡°íšŒ", "ë¸”ë¡œê·¸ ë¶„ì„ê¸°", "ë¸”ë¡œê·¸ í†µí•© ë¶„ì„"])

# íƒ­ 1: ì±„ë„ ë°ì´í„° ìˆ˜ì§‘ íƒ­
with tab1:
    st.subheader("ì±„ë„ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°")
    channel_url = st.text_input("ìœ íŠœë¸Œ ì±„ë„ ì£¼ì†Œ (e.g., https://youtube.com/@channelname)")
    keyword = st.text_input("ë™ì˜ìƒ ì œì‘ì— ì‚¬ìš©í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”")
    submit_button = st.button("ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥", type="primary")

    if submit_button and channel_url and keyword:
        try:
            with st.spinner("ì±„ë„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                analyzer = YouTubeAnalyzer(YOUTUBE_API_KEY)
                
                # ê³ ìœ  ê²€ìƒ‰ ID ìƒì„± (PostgreSQLì—ì„œ ìë™ìœ¼ë¡œ ìƒì„±)
                pk_id = search_unique_id()
                
                # ì±„ë„ ID ê°€ì ¸ì˜¤ê¸°
                channel_id = analyzer.get_channel_id(channel_url)
                
                # ì±„ë„ í†µê³„ ê°€ì ¸ì˜¤ê¸°
                channel_stats = analyzer.get_channel_stats(channel_id)
                
                # ì±„ë„ ì •ë³´ ì¶œë ¥
                st.subheader(f"ì±„ë„: {channel_stats['title']}")
                col1, col2 = st.columns([1, 3])
                with col1:
                    st.image(channel_stats['thumbnail'], width=150)
                with col2:
                    st.write(f"êµ¬ë…ì: {format_to_10k(channel_stats['subscribers'])} ({channel_stats['subscribers']}ëª…)")
                
                # ë™ì˜ìƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                videos = analyzer.get_all_videos(channel_id)
                
                # ìƒìœ„ 10ê°œ ë™ì˜ìƒë§Œ ì²˜ë¦¬ (ë˜ëŠ” ì „ì²´ ë™ì˜ìƒì´ 10ê°œ ë¯¸ë§Œì¸ ê²½ìš°)
                top_videos = videos[:10]
                
                st.subheader(f"ìƒìœ„ {len(top_videos)}ê°œ ë™ì˜ìƒ ë¶„ì„ ë° ì €ì¥ ì¤‘...")
                progress_bar = st.progress(0)
                
                # ê° ë™ì˜ìƒ ì •ë³´ ì²˜ë¦¬ ë° ì €ì¥
                for i, video in enumerate(top_videos):
                    video_id = video['video_id']
                    
                    is_shorts = is_youtubeshorts(video_id)  # ì‡¼ì¸  ì—¬ë¶€ í™•ì¸
                    transcript = youtube_transcript(video_id)  # ìë§‰ ê°€ì ¸ì˜¤ê¸°
                    view_subscriber_ratio = video['views'] / channel_stats['subscribers'] if channel_stats['subscribers'] > 0 else 0  # ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨ ê³„ì‚°
                    comments = analyzer.get_top_comments(video_id, 3)  # ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸°
                    
                    save_info(
                        'channel_info', pk_id, keyword, channel_url, channel_stats['title'], channel_stats['subscribers'], 
                        video_id, video['title'], video['thumbnail'], video['views'], video['like_count'], video['comment_count'], view_subscriber_ratio,
                        is_shorts, transcript, video['published_at'], comments
                    )
                    
                    progress_bar.progress((i + 1) / len(top_videos))  # ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
                
                st.success(f"ì„±ê³µì ìœ¼ë¡œ ì±„ë„ '{channel_stats['title']}'ì˜ ë°ì´í„°ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤!")

        except Exception as e:
            st.error(f"ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    elif submit_button:
        st.warning("ëª¨ë“  í•„ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”: ì±„ë„ URL, í‚¤ì›Œë“œ, ê²€ìƒ‰ ID")

# íƒ­ 2: í‚¤ì›Œë“œ ê¸°ë°˜ ë°ì´í„° ìˆ˜ì§‘ íƒ­
with tab2:
    st.subheader("í‚¤ì›Œë“œë¡œ ìœ íŠœë¸Œ ë™ì˜ìƒ ê²€ìƒ‰í•˜ê¸°")
    
    query = st.text_input("ë¶„ì„í•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
    max_results = st.slider("ë¶„ì„í•  ì˜ìƒ ìˆ˜", 10, 50, 30)
    search_button = st.button("ê²€ìƒ‰ ì‹œì‘", type="primary")

    if query and search_button:
        with st.spinner("ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                # ê²€ìƒ‰ ê³ ìœ  ID ìƒì„±
                pk_id = search_unique_id()

                df = fetch_youtube_data(query, max_results)
                
                st.subheader("ğŸ“Š ê¸°ë³¸ í†µê³„")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ì´ ì¡°íšŒìˆ˜", f"{df['views'].sum():,}")
                with col2:
                    st.metric("í‰ê·  ì¢‹ì•„ìš”", f"{int(df['likes'].mean()):,}")
                with col3:
                    st.metric("í‰ê·  ëŒ“ê¸€", f"{int(df['comments'].mean()):,}")
                
                # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                progress_bar = st.progress(0)
                st.text("ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì¤‘...")
                
                # YouTube API ê°ì²´ ìƒì„± (ëŒ“ê¸€ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•¨)
                analyzer = YouTubeAnalyzer(YOUTUBE_API_KEY)
                
                # ê° ë™ì˜ìƒ ì •ë³´ ì²˜ë¦¬ ë° ì €ì¥
                for i, (_, video) in enumerate(df.iterrows()):
                    video_id = video['url'].split('v=')[1] if 'v=' in video['url'] else video['url'].split('/')[-1]
                    
                    # ëŒ“ê¸€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    comments = analyzer.get_top_comments(video_id, 3)
                    
                    # channel_url ìƒì„± (ì±„ë„ ì´ë¦„ìœ¼ë¡œë¶€í„°)
                    channel_url = f"https://www.youtube.com/channel/{video_id}"
                    
                    # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                    save_info(
                        'keyword_info', pk_id, query, channel_url, video['channel'], video['subscribers'],
                        video_id, video['title'], video['thumbnail'], video['views'], video['likes'], video['comments'], video['view_sub_ratio'],
                        video['is_shorts'], video['1min_script'], video['publishedAt'], comments
                    )
                    
                    # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                    progress_bar.progress((i + 1) / len(df))
                
                st.success(f"ì„±ê³µì ìœ¼ë¡œ í‚¤ì›Œë“œ '{query}'ì— ëŒ€í•œ {len(df)}ê°œì˜ ë™ì˜ìƒ ë°ì´í„°ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤! (ê²€ìƒ‰ ID: {pk_id})")
                
                st.subheader("ğŸ”¥ ì¸ê¸° ì˜ìƒ TOP 5")
                top_videos = df.nlargest(5, 'views')
                top_videos['views'] = top_videos['views'].apply(lambda x: format_to_10k(x) + " ê±´")
                top_videos['subscribers'] = top_videos['subscribers'].apply(lambda x: format_to_10k(x) + " ëª…")
                top_videos['view_sub_ratio'] = top_videos['view_sub_ratio'].apply(lambda x: f"{round(x)}%")
                top_videos['thumbnail'] = top_videos.apply(lambda x: f'<a href="{x["url"]}" target="_blank"><img src="{x["thumbnail"]}" width="240"/></a>', axis=1)
                display_videos = top_videos[['thumbnail', 'title', 'channel', 'views', 'subscribers', 'view_sub_ratio', 'is_shorts', '1min_script']]
                display_videos.columns = ['ì¸ë„¤ì¼', 'ì œëª©', 'ì±„ë„ëª…', 'ì¡°íšŒìˆ˜', 'êµ¬ë…ììˆ˜', 'ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨', 'ì‡¼ì¸ ', 'ìµœì´ˆ 3ë¶„ ìŠ¤í¬ë¦½íŠ¸']
                display_videos['ì‡¼ì¸ '] = display_videos['ì‡¼ì¸ '].map({True: 'ì‡¼ì¸ ', False: 'ë¡±í¼'})
                st.markdown(display_videos.to_html(escape=False, index=False), unsafe_allow_html=True)
                
                df['engagement_rate'] = (df['likes'] + df['comments']) / df['views'] * 100
                st.subheader("ğŸ“ˆ ì°¸ì—¬ë„ ë¶„ì„")
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("í‰ê·  ì°¸ì—¬ìœ¨", f"{df['engagement_rate'].mean():.2f}%")
                with col2:
                    st.metric("ìµœê³  ì°¸ì—¬ìœ¨", f"{df['engagement_rate'].max():.2f}%")
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# íƒ­ 3: ì±„ë„ ë°ì´í„° ì¡°íšŒ íƒ­
with tab3:
    st.subheader("ì €ì¥ëœ ì±„ë„ ë°ì´í„° ì¡°íšŒ")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'search_clicked_tab3' not in st.session_state:
        st.session_state.search_clicked_tab3 = False
    if 'shorts_analyzed_tab3' not in st.session_state:
        st.session_state.shorts_analyzed_tab3 = False
    if 'longform_analyzed_tab3' not in st.session_state:
        st.session_state.longform_analyzed_tab3 = False
    if 'shorts_analysis_result_tab3' not in st.session_state:
        st.session_state.shorts_analysis_result_tab3 = None
    if 'longform_analysis_result_tab3' not in st.session_state:
        st.session_state.longform_analysis_result_tab3 = None
    if 'found_data_tab3' not in st.session_state:
        st.session_state.found_data_tab3 = None
    
    # ë¨¼ì € ëª¨ë“  ì±„ë„ë³„ ìµœê³  ì„±ê³¼ ë™ì˜ìƒ í‘œì‹œ
    st.subheader("ê²€ìƒ‰IDë³„ ìµœê³  ì„±ê³¼ ë™ì˜ìƒ ëª©ë¡")
    
    try:
        top_videos_df = get_top_videos_by_search_id('channel_info')
        
        if not top_videos_df.empty:
            # ë°ì´í„° í‘œì‹œ
            st.dataframe(
                top_videos_df,
                column_config={
                    "ì¸ë„¤ì¼": st.column_config.ImageColumn(width="large", help="ì˜ìƒ ì¸ë„¤ì¼"),
                    "ê²€ìƒ‰ID": st.column_config.Column(width="small", help="ì´ IDë¥¼ ì•„ë˜ ì…ë ¥ë€ì— ì…ë ¥í•˜ì—¬ ìƒì„¸ ë¶„ì„"),
                    "í‚¤ì›Œë“œ": st.column_config.Column(width="medium"),
                    "ì±„ë„ëª…": st.column_config.Column(width="medium"), 
                    "ì œëª©": st.column_config.Column(width="large"),
                    "ì¡°íšŒìˆ˜": st.column_config.Column(width="small"),
                    "ì¢‹ì•„ìš”": st.column_config.Column(width="small"),
                    "ëŒ“ê¸€ìˆ˜": st.column_config.Column(width="small"),
                    "ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨": st.column_config.Column(width="small"),
                    "ì‡¼ì¸ ": st.column_config.Column(width="small")
                },
                hide_index=True,
                use_container_width=True,
                height=300
            )
            
            # ID ì„ íƒì— ë„ì›€ì´ ë˜ëŠ” ì •ë³´ ì¶”ê°€
            st.info("ğŸ‘† ìœ„ ëª©ë¡ì—ì„œ ìƒì„¸ ë¶„ì„í•˜ê³  ì‹¶ì€ ê²€ìƒ‰IDë¥¼ í™•ì¸í•˜ê³ , ì•„ë˜ì— ì…ë ¥í•˜ì„¸ìš”.")
        else:
            st.warning("ì €ì¥ëœ ì±„ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error(f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # êµ¬ë¶„ì„  ì¶”ê°€
    st.markdown("---")
    
    # íŠ¹ì • ì±„ë„ ìƒì„¸ ë¶„ì„ ì„¹ì…˜
    st.subheader("íŠ¹ì • ê²€ìƒ‰ID ìƒì„¸ ë¶„ì„")
    search_id_input = st.number_input("ë¶„ì„í•  ê²€ìƒ‰ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”", min_value=1, step=1)
    
    # ê²€ìƒ‰ ë²„íŠ¼ ì½œë°±
    def on_search_click_tab3():
        st.session_state.search_clicked_tab3 = True
        st.session_state.shorts_analyzed_tab3 = False
        st.session_state.longform_analyzed_tab3 = False
        st.session_state.shorts_analysis_result_tab3 = None
        st.session_state.longform_analysis_result_tab3 = None
        st.session_state.found_data_tab3 = None  # ìƒˆ ê²€ìƒ‰ ì‹œ ë°ì´í„° ì´ˆê¸°í™”
        
    # ì‡¼ì¸  ë¶„ì„ ë²„íŠ¼ ì½œë°±
    def on_analyze_shorts_click_tab3():
        st.session_state.longform_analyzed_tab3 = True
    
    # ë¡±í¼ ë¶„ì„ ë²„íŠ¼ ì½œë°±
    def on_analyze_longform_click_tab3():
        st.session_state.longform_analyzed_tab3 = True
    
    search_button = st.button("ê²€ìƒ‰", type="primary", key="search_button_tab3", on_click=on_search_click_tab3)
    
    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
    if st.session_state.search_clicked_tab3:
        try:
            if 'found_data_tab3' not in st.session_state or st.session_state.found_data_tab3 is None:
                display_df = get_info(search_id_input, 'channel_info')
                st.session_state.found_data_tab3 = display_df
            else:
                display_df = st.session_state.found_data_tab3
            
            if not display_df.empty:
                st.success(f"ê²€ìƒ‰ ID {search_id_input}ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                
                # ì‡¼ì¸ ì™€ ë¡±í¼ ì˜ìƒ ë¶„ë¦¬í•´ì„œ í†µê³„ í‘œì‹œ
                shorts_df = display_df[display_df['ì‡¼ì¸ '] == True]
                longform_df = display_df[display_df['ì‡¼ì¸ '] == False]
                
                col1, col2 = st.columns(2)
                with col1:
                    st.subheader("ì‡¼ì¸  ì˜ìƒ")
                    st.write(f"ì˜ìƒ ìˆ˜: {len(shorts_df)}")
                    if not shorts_df.empty:
                        st.write(f"í‰ê·  ì¡°íšŒìˆ˜: {shorts_df['ì¡°íšŒìˆ˜'].mean():.1f}")
                        st.write(f"í‰ê·  ì¢‹ì•„ìš”: {shorts_df['ì¢‹ì•„ìš”'].mean():.1f}")
                
                with col2:
                    st.subheader("ë¡±í¼ ì˜ìƒ")
                    st.write(f"ì˜ìƒ ìˆ˜: {len(longform_df)}")
                    if not longform_df.empty:
                        st.write(f"í‰ê·  ì¡°íšŒìˆ˜: {longform_df['ì¡°íšŒìˆ˜'].mean():.1f}")
                        st.write(f"í‰ê·  ì¢‹ì•„ìš”: {longform_df['ì¢‹ì•„ìš”'].mean():.1f}")
                
                # ì „ì²´ ë°ì´í„° í‘œì‹œ
                st.subheader("ëª¨ë“  ì˜ìƒ ë°ì´í„°")
                st.dataframe(
                    display_df,
                    column_config={
                        "ì¸ë„¤ì¼": st.column_config.ImageColumn(width="large", help="ì˜ìƒ ì¸ë„¤ì¼"),
                        "ì±„ë„ëª…": st.column_config.Column(width="medium"), 
                        "ì œëª©": st.column_config.Column(width="large"),
                        "ì¡°íšŒìˆ˜": st.column_config.Column(width="small"),
                        "ì¢‹ì•„ìš”": st.column_config.Column(width="small"),
                        "ëŒ“ê¸€ìˆ˜": st.column_config.Column(width="small"),
                        "ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨": st.column_config.Column(width="small"),
                        "ì‡¼ì¸ ": st.column_config.Column(width="small"), 
                        "ëŒ“ê¸€1": st.column_config.Column(width="large"), 
                        "ëŒ“ê¸€2": st.column_config.Column(width="large"), 
                        "ëŒ“ê¸€3": st.column_config.Column(width="large"), 
                        "ìŠ¤í¬ë¦½íŠ¸": st.column_config.TextColumn(width="large")
                    },
                    hide_index=True,
                    use_container_width=True,
                    height=600
                )
                
                # ë¶„ì„ ì„¹ì…˜
                st.subheader("ì±„ë„ ë°ì´í„° ë¶„ì„í•˜ê¸°")
                
                # 1. ì‡¼ì¸  ë¶„ì„ ì„¹ì…˜
                st.write("### ì‡¼ì¸  ì˜ìƒ ë¶„ì„")
                
                if len(shorts_df) == 0:
                    st.info("í•´ë‹¹ ì±„ë„ì—ëŠ” ì‡¼ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # ì‡¼ì¸  ë¶„ì„ ë²„íŠ¼
                    if not st.session_state.shorts_analyzed_tab3:
                        shorts_btn = st.button(
                            "ì‡¼ì¸  ë¶„ì„ ì‹œì‘", 
                            type="primary", 
                            key="btn_analyze_shorts",
                            on_click=on_analyze_shorts_click_tab3
                        )
                    
                    # ë¶„ì„ ìˆ˜í–‰ ë° ê²°ê³¼ í‘œì‹œ
                    if st.session_state.shorts_analyzed_tab3:
                        if st.session_state.shorts_analysis_result_tab3 is None:
                            with st.spinner("ì‡¼ì¸  ì˜ìƒ ë¶„ì„ ì¤‘..."):
                                # ì‡¼ì¸  ë¶„ì„ ìˆ˜í–‰
                                shorts_analysis = analyze_video_data(openai_client, display_df, is_shorts=True)
                                st.session_state.shorts_analysis_result_tab3 = shorts_analysis
                                
                                # ë¶„ì„ ë‚´ìš© ì €ì¥
                                for _, row in shorts_df.iterrows():
                                    save_video_analysis(search_id_input, row['video_id'], row['ì œëª©'], True, shorts_analysis)
                                
                                st.success("ì‡¼ì¸  ì˜ìƒ ë¶„ì„ ì™„ë£Œ ë° ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        
                        # ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                        st.write(st.session_state.shorts_analysis_result_tab3)
                
                # êµ¬ë¶„ì„ 
                st.markdown("---")
                
                # 2. ë¡±í¼ ë¶„ì„ ì„¹ì…˜
                st.write("### ë¡±í¼ ì˜ìƒ ë¶„ì„")
                
                if len(longform_df) == 0:
                    st.info("í•´ë‹¹ ì±„ë„ì—ëŠ” ë¡±í¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # ë¡±í¼ ë¶„ì„ ë²„íŠ¼
                    if not st.session_state.longform_analyzed_tab3:
                        longform_btn = st.button(
                            "ë¡±í¼ ë¶„ì„ ì‹œì‘", 
                            type="primary", 
                            key="btn_analyze_longform",
                            on_click=on_analyze_longform_click_tab3
                        )
                    
                    # ë¶„ì„ ìˆ˜í–‰ ë° ê²°ê³¼ í‘œì‹œ
                    if st.session_state.longform_analyzed_tab3:
                        if st.session_state.longform_analysis_result_tab3 is None:
                            with st.spinner("ë¡±í¼ ì˜ìƒ ë¶„ì„ ì¤‘..."):
                                # ë¡±í¼ ë¶„ì„ ìˆ˜í–‰
                                longform_analysis = analyze_video_data(openai_client, display_df, is_shorts=False)
                                st.session_state.longform_analysis_result_tab3 = longform_analysis
                                
                                # ë¶„ì„ ë‚´ìš© ì €ì¥
                                for _, row in longform_df.iterrows():
                                    save_video_analysis(search_id_input, row['video_id'], row['ì œëª©'], False, longform_analysis)
                                
                                st.success("ë¡±í¼ ì˜ìƒ ë¶„ì„ ì™„ë£Œ ë° ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        
                        # ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                        st.write(st.session_state.longform_analysis_result_tab3)   
            else:
                st.warning(f"ê²€ìƒ‰ ID {search_id_input}ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                st.session_state.found_data_tab3 = None
        except Exception as e:
            st.error(f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.session_state.found_data_tab3 = None

# íƒ­ 4: í‚¤ì›Œë“œ ë°ì´í„° ì¡°íšŒ íƒ­
with tab4:
    st.subheader("ì €ì¥ëœ í‚¤ì›Œë“œ ë°ì´í„° ì¡°íšŒ")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'search_clicked_tab4' not in st.session_state:
        st.session_state.search_clicked_tab4 = False
    if 'shorts_analyzed_tab4' not in st.session_state:  # ì‡¼ì¸  ë¶„ì„ ì™„ë£Œ ì—¬ë¶€
        st.session_state.shorts_analyzed_tab4 = False
    if 'longform_analyzed_tab4' not in st.session_state:  # ë¡±í¼ ë¶„ì„ ì™„ë£Œ ì—¬ë¶€
        st.session_state.longform_analyzed_tab4 = False
    if 'shorts_analysis_result_tab4' not in st.session_state:  # ì‡¼ì¸  ë¶„ì„ ê²°ê³¼
        st.session_state.shorts_analysis_result_tab4 = None
    if 'longform_analysis_result_tab4' not in st.session_state:  # ë¡±í¼ ë¶„ì„ ê²°ê³¼
        st.session_state.longform_analysis_result_tab4 = None
    if 'found_data_tab4' not in st.session_state:
        st.session_state.found_data_tab4 = None
    
    # ë¨¼ì € ëª¨ë“  ì±„ë„ë³„ ìµœê³  ì„±ê³¼ ë™ì˜ìƒ í‘œì‹œ
    st.subheader("ê²€ìƒ‰IDë³„ ìµœê³  ì„±ê³¼ ë™ì˜ìƒ ëª©ë¡")
    
    try:
        top_videos_df = get_top_videos_by_search_id('keyword_info')
        
        if not top_videos_df.empty:
            # ë°ì´í„° í‘œì‹œ
            st.dataframe(
                top_videos_df,
                column_config={
                    "ì¸ë„¤ì¼": st.column_config.ImageColumn(width="large", help="ì˜ìƒ ì¸ë„¤ì¼"),
                    "ê²€ìƒ‰ID": st.column_config.Column(width="small", help="ì´ IDë¥¼ ì•„ë˜ ì…ë ¥ë€ì— ì…ë ¥í•˜ì—¬ ìƒì„¸ ë¶„ì„"),
                    "í‚¤ì›Œë“œ": st.column_config.Column(width="medium"),
                    "ì±„ë„ëª…": st.column_config.Column(width="medium"), 
                    "ì œëª©": st.column_config.Column(width="large"),
                    "ì¡°íšŒìˆ˜": st.column_config.Column(width="small"),
                    "ì¢‹ì•„ìš”": st.column_config.Column(width="small"),
                    "ëŒ“ê¸€ìˆ˜": st.column_config.Column(width="small"),
                    "ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨": st.column_config.Column(width="small"),
                    "ì‡¼ì¸ ": st.column_config.Column(width="small")
                },
                hide_index=True,
                use_container_width=True,
                height=300
            )
            
            # ID ì„ íƒì— ë„ì›€ì´ ë˜ëŠ” ì •ë³´ ì¶”ê°€
            st.info("ğŸ‘† ìœ„ ëª©ë¡ì—ì„œ ìƒì„¸ ë¶„ì„í•˜ê³  ì‹¶ì€ ê²€ìƒ‰IDë¥¼ í™•ì¸í•˜ê³ , ì•„ë˜ì— ì…ë ¥í•˜ì„¸ìš”.")
        else:
            st.warning("ì €ì¥ëœ ì±„ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error(f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # êµ¬ë¶„ì„  ì¶”ê°€
    st.markdown("---")
    
    # íŠ¹ì • ì±„ë„ ìƒì„¸ ë¶„ì„ ì„¹ì…˜
    st.subheader("íŠ¹ì • ê²€ìƒ‰ID ìƒì„¸ ë¶„ì„")
    search_id_input = st.number_input("í‚¤ì›Œë“œì— ëŒ€í•´ ì¡°íšŒí•  ê²€ìƒ‰ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”", min_value=1, step=1)
    
    # ê²€ìƒ‰ ë²„íŠ¼ ì½œë°±
    def on_search_click_tab4():
        st.session_state.search_clicked_tab4 = True
        st.session_state.shorts_analyzed_tab4 = False
        st.session_state.longform_analyzed_tab4 = False
        st.session_state.shorts_analysis_result_tab4 = None
        st.session_state.longform_analysis_result_tab4 = None
        st.session_state.found_data_tab4 = None  # ìƒˆ ê²€ìƒ‰ ì‹œ ë°ì´í„° ì´ˆê¸°í™”
        
    # ì‡¼ì¸  ë¶„ì„ ë²„íŠ¼ ì½œë°±
    def on_analyze_shorts_click_tab4():
        st.session_state.shorts_analyzed_tab4 = True
    
    # ë¡±í¼ ë¶„ì„ ë²„íŠ¼ ì½œë°±
    def on_analyze_longform_click_tab4():
        st.session_state.longform_analyzed_tab4 = True
    
    search_button_keyword = st.button("ê²€ìƒ‰", type="primary", key="search_button_keyword_tab4", on_click=on_search_click_tab4)
    
    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
    if st.session_state.search_clicked_tab4:
        try:
            if 'found_data_tab4' not in st.session_state or st.session_state.found_data_tab4 is None:
                display_df = get_info(search_id_input, 'keyword_info')
                st.session_state.found_data_tab4 = display_df
            else:
                display_df = st.session_state.found_data_tab4
            
            if not display_df.empty:
                st.success(f"ê²€ìƒ‰ ID {search_id_input}ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                
                # ì‡¼ì¸ ì™€ ë¡±í¼ ì˜ìƒ ë¶„ë¦¬í•´ì„œ í†µê³„ í‘œì‹œ
                shorts_df = display_df[display_df['ì‡¼ì¸ '] == True]
                longform_df = display_df[display_df['ì‡¼ì¸ '] == False]
                
                col1, col2 = st.columns(2)
                with col1:
                    st.subheader("ì‡¼ì¸  ì˜ìƒ")
                    st.write(f"ì˜ìƒ ìˆ˜: {len(shorts_df)}")
                    if not shorts_df.empty:
                        st.write(f"í‰ê·  ì¡°íšŒìˆ˜: {shorts_df['ì¡°íšŒìˆ˜'].mean():.1f}")
                        st.write(f"í‰ê·  ì¢‹ì•„ìš”: {shorts_df['ì¢‹ì•„ìš”'].mean():.1f}")
                
                with col2:
                    st.subheader("ë¡±í¼ ì˜ìƒ")
                    st.write(f"ì˜ìƒ ìˆ˜: {len(longform_df)}")
                    if not longform_df.empty:
                        st.write(f"í‰ê·  ì¡°íšŒìˆ˜: {longform_df['ì¡°íšŒìˆ˜'].mean():.1f}")
                        st.write(f"í‰ê·  ì¢‹ì•„ìš”: {longform_df['ì¢‹ì•„ìš”'].mean():.1f}")
                
                # ì „ì²´ ë°ì´í„° í‘œì‹œ
                st.subheader("ëª¨ë“  ì˜ìƒ ë°ì´í„°")
                # st.dataframe(display_df, use_container_width=True)
                st.dataframe(
                    display_df,
                    column_config={
                        "ì¸ë„¤ì¼": st.column_config.ImageColumn(width="large", help="ì˜ìƒ ì¸ë„¤ì¼"),
                        "ì±„ë„ëª…": st.column_config.Column(width="medium"), 
                        "ì œëª©": st.column_config.Column(width="large"),
                        "ì¡°íšŒìˆ˜": st.column_config.Column(width="small"),
                        "ì¢‹ì•„ìš”": st.column_config.Column(width="small"),
                        "ëŒ“ê¸€ ìˆ˜": st.column_config.Column(width="small"),
                        "ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨": st.column_config.Column(width="small"),
                        "ì‡¼ì¸ ": st.column_config.Column(width="small"), 
                        "ëŒ“ê¸€1": st.column_config.Column(width="large"), 
                        "ëŒ“ê¸€2": st.column_config.Column(width="large"), 
                        "ëŒ“ê¸€3": st.column_config.Column(width="large"), 
                        "ìŠ¤í¬ë¦½íŠ¸": st.column_config.TextColumn(width="large")
                    },
                    hide_index=True,
                    use_container_width=True,
                    height=600
                )
                
                # ë¶„ì„ ì„¹ì…˜
                st.subheader("ì±„ë„ ë°ì´í„° ë¶„ì„í•˜ê¸°")
        
        except Exception as e:
            st.error(f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.session_state.found_data_tab4 = None

# íƒ­ 5: ë¸”ë¡œê·¸ ë¶„ì„ê¸° íƒ­
with tab5:
    st.subheader("ë¸”ë¡œê·¸ ë¶„ì„ê¸°")

    analysis_keyword = st.text_input('ë¸”ë¡œê·¸ ë¶„ì„ì„ ìœ„í•œ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”. ë¶„ì„ ê·¸ë£¹ì˜ ì´ë¦„ì„ ê²°ì •í•©ë‹ˆë‹¤.')
    
    # # ë¸”ë¡œê·¸ í•œê°œ ë¶„ì„
    # blog_url = st.text_input('ë¶„ì„í•  ë¸”ë¡œê·¸ ì£¼ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš”.')  # ë‚˜ì¤‘ì— 10ê°œë¡œ ëŠ˜ë¦´ ì˜ˆì •
    # analyse_button = st.button("ë¸”ë¡œê·¸ ë¶„ì„ ì‹œì‘", type="primary")
    
    # if blog_url and analysis_keyword and analyse_button:
    #     with st.spinner("ë¸”ë¡œê·¸ ë‚´ìš©ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
    #         try:
    #             extracted_data = blog_content(blog_url)

    #             blog_summary = blog_summarizer(openai_client, extracted_data['content'])

    #             conn = connect_postgres()
    #             cur = conn.cursor()

    #             # RETURNING ì ˆ ì¶”ê°€
    #             cur.execute("""
    #             INSERT INTO blog_summary (keyword, url, summary) 
    #             VALUES (%s, %s, %s) RETURNING id
    #             """, (analysis_keyword, blog_url, blog_summary))
                
    #             # ë°˜í™˜ëœ id ê°€ì ¸ì˜¤ê¸°
    #             inserted_id = cur.fetchone()[0]

    #             conn.commit()
    #             cur.close()
    #             conn.close()

    #             st.subheader("ë¸”ë¡œê·¸ ìš”ì•½ ê²°ê³¼")
    #             st.write(blog_summary)
                
    #             st.success(f"ë¸”ë¡œê·¸ ë¶„ì„ ê²°ê³¼ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! (ID: {inserted_id})")
    #         except Exception as e:
    #             st.error(f"ë¸”ë¡œê·¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # # ë¸”ë¡œê·¸ ì—¬ëŸ¬ê°œ ë¶„ì„
    blog_urls_container = st.container()  # ì»¨í…Œì´ë„ˆ ìƒì„±
    
    # ì„¸ì…˜ ìƒíƒœì— URL ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    if 'blog_urls' not in st.session_state:
        st.session_state.blog_urls = [""] * 10  # 10ê°œì˜ ë¹ˆ URLë¡œ ì´ˆê¸°í™”
    
    # 5ê°œì”© ë‘ ì—´ë¡œ ë‚˜ëˆ ì„œ URL ì…ë ¥ í•„ë“œ ìƒì„±
    col1, col2 = st.columns(2)
    
    # ì™¼ìª½ ì»¬ëŸ¼ (0-4ë²ˆ URL)
    with col1:
        for i in range(5):
            st.text_input(
                f"ë¸”ë¡œê·¸ ì£¼ì†Œ {i+1}",
                value=st.session_state.blog_urls[i],
                key=f"blog_url_{i}"
            )
            # ì…ë ¥ í›„ ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            st.session_state.blog_urls[i] = st.session_state[f"blog_url_{i}"]
    
    # ì˜¤ë¥¸ìª½ ì»¬ëŸ¼ (5-9ë²ˆ URL)
    with col2:
        for i in range(5, 10):
            st.text_input(
                f"ë¸”ë¡œê·¸ ì£¼ì†Œ {i+1}",
                value=st.session_state.blog_urls[i],
                key=f"blog_url_{i}"
            )
            # ì…ë ¥ í›„ ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            st.session_state.blog_urls[i] = st.session_state[f"blog_url_{i}"]
    
    # ìœ íš¨í•œ URLì˜ ìˆ˜ ê³„ì‚° (ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ URL)
    valid_urls = [url for url in st.session_state.blog_urls if url.strip()]
    
    # ë¶„ì„ ë²„íŠ¼ê³¼ ìƒíƒœ í‘œì‹œ
    analyse_button = st.button("ë¸”ë¡œê·¸ ë¶„ì„ ì‹œì‘", type="primary", disabled=len(valid_urls) == 0 or not analysis_keyword)
    
    # ë¸”ë¡œê·¸ ë¶„ì„ ì‹¤í–‰
    if analysis_keyword and valid_urls and analyse_button:
        results_container = st.container()  # ë¶„ì„ ê²°ê³¼ ì €ì¥ìš© ì»¨í…Œì´ë„ˆ

        progress_bar = st.progress(0)  # ì§„í–‰ ìƒí™© í‘œì‹œ
        
        # ì„±ê³µ ë° ì‹¤íŒ¨ ê²°ê³¼ ìˆ˜ì§‘
        success_count = 0
        failed_urls = []
        saved_ids = []
        
        # ê° URL ì²˜ë¦¬
        for i, url in enumerate(valid_urls):
            try:
                with st.spinner(f"ë¸”ë¡œê·¸ ë¶„ì„ ì¤‘... ({i+1}/{len(valid_urls)})"):
                    extracted_data = blog_content(url)  # ë¸”ë¡œê·¸ ë‚´ìš© ì¶”ì¶œ
                    
                    blog_summary = blog_summarizer(openai_client, extracted_data['content'])  # ë¸”ë¡œê·¸ ìš”ì•½
                    
                    # DBì— ì €ì¥
                    conn = connect_postgres()
                    cur = conn.cursor()
                    
                    cur.execute("""INSERT INTO blog_summary (keyword, url, summary) VALUES (%s, %s, %s) RETURNING id""", (analysis_keyword, url, blog_summary))
                    
                    inserted_id = cur.fetchone()[0]
                    saved_ids.append(inserted_id)
                    
                    conn.commit()
                    cur.close()
                    conn.close()
                    
                    # ì„±ê³µ ì¹´ìš´íŠ¸ ì¦ê°€
                    success_count += 1
                
            except Exception as e:
                # ì‹¤íŒ¨í•œ URL ê¸°ë¡
                failed_urls.append((url, str(e)))
                
                # ì—ëŸ¬ ë°œìƒ ì‹œ DB ì—°ê²° ë‹«ê¸°
                try:
                    if 'conn' in locals() and conn:
                        conn.rollback()
                        cur.close()
                        conn.close()
                except:
                    pass
            
            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            progress_bar.progress((i + 1) / len(valid_urls))
        
        # ë¶„ì„ ì™„ë£Œ í›„ ê²°ê³¼ í‘œì‹œ
        with results_container:
            st.subheader("ë¸”ë¡œê·¸ ë¶„ì„ ê²°ê³¼")
            
            if success_count > 0:
                st.success(f"{success_count}ê°œì˜ ë¸”ë¡œê·¸ê°€ ì„±ê³µì ìœ¼ë¡œ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                # ì €ì¥ëœ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                conn = connect_postgres()
                cur = conn.cursor()
                
                # IN êµ¬ë¬¸ì„ ìœ„í•œ ë¬¸ìì—´ ìƒì„±
                ids_str = ",".join(str(id) for id in saved_ids)
                
                if ids_str:
                    cur.execute(f"""SELECT id, url, summary FROM blog_summary WHERE id IN ({ids_str}) ORDER BY id""")
                    results = cur.fetchall()
                    
                    cur.close()
                    conn.close()
                    
                    # ê²°ê³¼ í‘œì‹œ
                    for result in results:
                        with st.expander(f"ë¸”ë¡œê·¸: {result[1]}"):
                            st.markdown(f"**ID**: {result[0]}")
                            st.markdown("**ìš”ì•½**:")
                            st.write(result[2])
            
            # ì‹¤íŒ¨í•œ URL í‘œì‹œ
            if failed_urls:
                st.error(f"{len(failed_urls)}ê°œì˜ ë¸”ë¡œê·¸ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                for url, error in failed_urls:
                    with st.expander(f"ì‹¤íŒ¨í•œ URL: {url}"):
                        st.error(f"ì˜¤ë¥˜: {error}")
   
# íƒ­ 6: ë¸”ë¡œê·¸ í†µí•© ë¶„ì„ íƒ­
with tab6:
    st.subheader("ë¸”ë¡œê·¸ í†µí•© ë¶„ì„")

    load_keyword = st.text_input('í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”. í•´ë‹¹ í‚¤ì›Œë“œë¡œ ê·¸ë£¨í•‘ëœ ë¸”ë¡œê·¸ ë‚´ìš©ë“¤ì„ í†µí•© ë¶„ì„í•©ë‹ˆë‹¤.')
    int_analyse_button = st.button("í†µí•© ë¶„ì„ ì‹œì‘", type="primary")  # integrated analysis
    
    if load_keyword and int_analyse_button:
        with st.spinner(f"í‚¤ì›Œë“œ '{load_keyword}'ë¡œ ì €ì¥ëœ ë¸”ë¡œê·¸ ìš”ì•½ì„ í†µí•© ë¶„ì„ ì¤‘..."):
            try:
                # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í•´ë‹¹ í‚¤ì›Œë“œë¡œ ì €ì¥ëœ ìš”ì•½ ì¡°íšŒ
                conn = connect_postgres()
                cur = conn.cursor()
                
                cur.execute("""
                SELECT summary FROM blog_summary 
                WHERE keyword = %s
                """, (load_keyword,))
                
                summaries = [row[0] for row in cur.fetchall()]
                
                # ì¡°íšŒëœ ìš”ì•½ì´ ì—†ëŠ” ê²½ìš°
                if not summaries:
                    st.error(f"í‚¤ì›Œë“œ '{load_keyword}'ë¡œ ì €ì¥ëœ ë¸”ë¡œê·¸ ìš”ì•½ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # í†µí•© ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì‘ì„±
                    prompt = f"""
ë‹¤ìŒì€ "{load_keyword}" í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ {len(summaries)}ê°œì˜ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìš”ì•½ì…ë‹ˆë‹¤:

"""
                    for i, summary in enumerate(summaries):
                        prompt += f"\n--- ë¸”ë¡œê·¸ {i+1} ---\n{summary}\n"
                    
                    prompt += f"""
ìœ„ì˜ ë¸”ë¡œê·¸ ìš”ì•½ë“¤ì„ í†µí•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬, ë‹¤ìŒ ì‚¬í•­ì„ í¬í•¨í•œ í¬ê´„ì ì¸ ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

1. ì£¼ìš” ë‚´ìš© ë° ê³µí†µ ì£¼ì œ
2. ì¤‘ìš”í•œ ì‚¬ì‹¤ì´ë‚˜ ì •ë³´
3. ì„œë¡œ ë‹¤ë¥¸ ê´€ì ì´ë‚˜ ì˜ê²¬ (ìˆëŠ” ê²½ìš°)
4. ê´€ë ¨ ì´ë²¤íŠ¸ë‚˜ ì¼ì • (ìˆëŠ” ê²½ìš°)
5. ì „ì²´ ë‚´ìš©ì„ ì¢…í•©í•œ í†µì°°

"{load_keyword}" í‚¤ì›Œë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì´ ëª¨ë“  ë¸”ë¡œê·¸ ë‚´ìš©ì„ ì˜ í†µí•©í•´ì„œ ìš”ì•½í•´ì£¼ì„¸ìš”.
"""
                    
                    # OpenAI APIë¥¼ í†µí•œ í†µí•© ë¶„ì„
                    response = openai_client.chat.completions.create(
                        model="gpt-4o-2024-08-06",
                        messages=[
                            {"role": "system", "content": "ë‹¹ì‹ ì€ ì—¬ëŸ¬ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì˜ ìš”ì•½ì„ í†µí•©í•˜ì—¬ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.3,
                        max_tokens=1500
                    )
                    
                    integrated_summary = response.choices[0].message.content.strip()
                    
                    # ê³ ìœ  ID ìƒì„±
                    search_id = search_unique_id()
                    
                    # í†µí•© ë¶„ì„ ê²°ê³¼ ì €ì¥
                    cur.execute("""
                    INSERT INTO blog_int_summary (search_unique_id, keyword, int_summary)
                    VALUES (%s, %s, %s)
                    """, (search_id, load_keyword, integrated_summary))
                    
                    conn.commit()
                    
                    # ì„±ê³µ ë©”ì‹œì§€ í‘œì‹œ
                    st.success(f"{len(summaries)}ê°œì˜ ë¸”ë¡œê·¸ ìš”ì•½ì´ ì„±ê³µì ìœ¼ë¡œ í†µí•© ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    
                    # ê²°ê³¼ í‘œì‹œ
                    st.subheader("í†µí•© ë¶„ì„ ê²°ê³¼")
                    st.write(integrated_summary)
                
                cur.close()
                conn.close()
                
            except Exception as e:
                st.error(f"í†µí•© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                # ì—ëŸ¬ ë°œìƒ ì‹œ ì—°ê²° ë‹«ê¸°
                try:
                    if 'conn' in locals() and conn:
                        conn.rollback()
                        cur.close()
                        conn.close()
                except:
                    pass
