import streamlit as st
import os
from dotenv import load_dotenv
import requests
import time
import pandas as pd
import datetime

from googleapiclient.discovery import build
from youtube_transcript_api import YouTubeTranscriptApi

from openai import OpenAI

import psycopg2
from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT

from extract_blog_content import blog_content
from analyse_video import analyze_channel_video, analyze_keyword_video


st.set_page_config(page_title="ìœ íŠœë¸Œ ì±„ë„ ë¶„ì„ê¸°", layout="wide")

load_dotenv()

YOUTUBE_API_KEY = os.getenv('YOUTUBE_API_KEY')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

openai_client = OpenAI(api_key=OPENAI_API_KEY)

llm_option = st.selectbox("LLM ì„ íƒ", ('gpt-4o-2024-08-06', 'gpt-4o-mini-2024-07-18', 'gpt-3.5-turbo-0125'))  # 'o1-mini-2024-09-12'


# ìœ íŠœë¸Œ ì‡¼ì¸ ì¸ì§€ ì•„ë‹Œì§€ êµ¬ë¶„
def is_youtubeshorts(video_id):
    url = 'https://www.youtube.com/shorts/' + video_id
    req = requests.head(url)
    
    return req.status_code == 200

# YouTube Transcript APIë¡œ ìŠ¤í¬ë¦½íŠ¸ ìš”ì•½
def youtube_transcript(video_id, max_retries=3, retry_delay=1.5):
    """
    YouTube ë™ì˜ìƒì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜.
    max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
    retry_delay: ì¬ì‹œë„ ì‚¬ì´ì˜ ëŒ€ê¸° ì‹œê°„(ì´ˆ)
    """
    for retry in range(max_retries):
        try:
            if retry > 0:
                print(f"ìë§‰ ì¶”ì¶œ ì¬ì‹œë„ ì¤‘... ({retry}/{max_retries-1})")
                time.sleep(retry_delay)  # ì¬ì‹œë„ ì‚¬ì´ì— ëŒ€ê¸° ì‹œê°„ ì¶”ê°€
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ìë§‰ ëª©ë¡ í™•ì¸
            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
            
            # ë””ë²„ê¹…ì„ ìœ„í•´ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ìë§‰ ì¶œë ¥
            print(f"\nì˜ìƒ ID {video_id}ì˜ ì‚¬ìš© ê°€ëŠ¥í•œ ìë§‰ ëª©ë¡:")
            for transcript in transcript_list:
                print(f"- {transcript.language} ({transcript.language_code}): {'ìë™ ìƒì„±' if transcript.is_generated else 'ìˆ˜ë™ ìƒì„±'}")
            
            transcript = None
            
            # ìˆœì°¨ì ìœ¼ë¡œ ìë§‰ ì‹œë„
            try:
                # 1. ìˆ˜ë™ í•œêµ­ì–´ ìë§‰
                transcript = transcript_list.find_manually_created_transcript(['ko'])
                print('ìˆ˜ë™ ìƒì„± í•œêµ­ì–´ ìë§‰ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.')
            except Exception as e1:
                try:
                    # 2. ìë™ ìƒì„± í•œêµ­ì–´ ìë§‰
                    transcript = transcript_list.find_generated_transcript(['ko'])
                    print('ìë™ ìƒì„± í•œêµ­ì–´ ìë§‰ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.')
                except Exception as e2:
                    try:
                        # 3. ë‹¤ë¥¸ í˜•ì‹ì˜ í•œêµ­ì–´ ìë§‰
                        for t in transcript_list:
                            if t.language_code.startswith('ko'):
                                transcript = t
                                print(f'í•œêµ­ì–´ ìë§‰ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤: {t.language_code} ({"ìë™ ìƒì„±" if t.is_generated else "ìˆ˜ë™ ìƒì„±"})')
                                break
                    except Exception as e3:
                        print('í•œêµ­ì–´ ìë§‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
                        # ê³„ì† ì§„í–‰í•˜ì—¬ ë‹¤ë¥¸ ì‹œë„ë¥¼ í•´ë³´ê¸° ìœ„í•´ continue í•˜ì§€ ì•ŠìŒ
            
            if transcript:
                try:
                    # ìë§‰ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    transcript_data = transcript.fetch()
                    first_minute = []
                    current_time = 0
                    
                    for line in transcript_data:
                        if current_time > 180:  # 180ì´ˆ = 3ë¶„
                            break
                        first_minute.append(line['text'])
                        current_time += line['duration']
                    
                    result = ' '.join(first_minute)
                    if result:
                        print(f'ì„±ê³µì ìœ¼ë¡œ {current_time:.1f}ì´ˆ ë¶„ëŸ‰ì˜ ìë§‰ì„ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.')
                        return result
                    else:
                        print('ìë§‰ì€ ì°¾ì•˜ìœ¼ë‚˜ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.')
                except Exception as e:
                    print(f'ìë§‰ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}')
            else:
                print('ì‚¬ìš© ê°€ëŠ¥í•œ ìë§‰ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')
                
        except Exception as e:
            print(f'ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}')
        
        # ì¬ì‹œë„ê°€ ë‚¨ì•„ ìˆìœ¼ë©´ ê³„ì† ì‹œë„
        if retry < max_retries - 1:
            continue
    
    # ëª¨ë“  ì‹œë„ê°€ ì‹¤íŒ¨í•˜ë©´ ëª…í™•í•œ ë©”ì‹œì§€ ë°˜í™˜
    return "âš ï¸ ìë§‰ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ì—¬ëŸ¬ ë²ˆ ì‹œë„í–ˆìœ¼ë‚˜ ì‹¤íŒ¨)"

# ë§Œ ë‹¨ìœ„ë¡œ ë³€í™˜
def format_to_10k(n):
    num = round(n / 10000, 1)  # ì†Œìˆ˜ì  ì²«ì§¸ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼
    return f"{num}ë§Œ"


# PostgreSQLì— ì ‘ì†
def connect_postgres():
    conn = psycopg2.connect(
        host="15.164.112.237", 
        database="dify", 
        user="difyuser", 
        password="bico0218"
    )
    conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
    
    return conn

def search_unique_id():
    conn = connect_postgres()
    cur = conn.cursor()
    
    # ì‹œí€€ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒì„±
    cur.execute("CREATE SEQUENCE IF NOT EXISTS youtube_search_seq")
    
    # ë‹¤ìŒ ì‹œí€€ìŠ¤ ê°’ ê°€ì ¸ì˜¤ê¸°
    cur.execute("SELECT nextval('youtube_search_seq')")
    search_id = cur.fetchone()[0]
    
    cur.close()
    conn.close()
    
    return search_id

# ì±„ë„ ì •ë³´ ì €ì¥
def save_info(table_name, search_unique_id, keyword, channel_url, channel_name, channel_subscribers, 
              video_id, video_title, video_thumbnail, video_view_count, video_like_count, video_comment_count, video_view_subscriber_ratio, 
              is_shorts, transcript, published_at, top_comments):
    conn = connect_postgres()
    cur = conn.cursor()
    
    # ëŒ“ê¸€ ì •ë³´ ì¤€ë¹„ (ê° ëŒ“ê¸€ì„ ë³„ë„ ë³€ìˆ˜ë¡œ)
    comment_1 = ""
    comment_2 = ""
    comment_3 = ""
    
    # ëŒ“ê¸€ ì •ë³´ ì¤€ë¹„ (ë‚´ìš©ë§Œ ì €ì¥)
    comment_1 = comments[0]['text'] if len(comments) > 0 else "ë‚´ìš© ì—†ìŒ"
    comment_2 = comments[1]['text'] if len(comments) > 1 else "ë‚´ìš© ì—†ìŒ"
    comment_3 = comments[2]['text'] if len(comments) > 2 else "ë‚´ìš© ì—†ìŒ"
    
    cur.execute(f"""
    INSERT INTO {table_name} (
        search_unique_id, keyword, channel_url, channel_name, channel_subscribers, 
        video_id, video_title, video_thumbnail, video_view_count, video_like_count, video_comment_count, video_view_subscriber_ratio, 
        is_shorts, transcript, published_at, comment_1, comment_2, comment_3)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """, 
        (search_unique_id, keyword, channel_url, channel_name, channel_subscribers, 
         video_id, video_title, video_thumbnail, video_view_count, video_like_count, video_comment_count, video_view_subscriber_ratio, 
         is_shorts, transcript, published_at, comment_1, comment_2, comment_3)
    )
    
    conn.commit()
    cur.close()
    conn.close()

# ìœ íŠœë¸Œ ì±„ë„ ë°ì´í„° ìˆ˜ì§‘
class YouTubeAnalyzer:
    def __init__(self, api_key):
        self.youtube = build('youtube', 'v3', developerKey=api_key)
    
    # Extract channel ID from URL or custom URL
    def get_channel_id(self, channel_url):
        if 'youtube.com/channel/' in channel_url:
            return channel_url.split('channel/')[1].split('/')[0]
        elif 'youtube.com/@' in channel_url:
            username = channel_url.split('@')[1].split('/')[0]
            request = self.youtube.channels().list(
                part='id',
                forUsername=username
            )
            try:
                response = request.execute()
                if response.get('items'):
                    return response['items'][0]['id']
            except:
                pass
            
            # If the above method fails, try with search
            request = self.youtube.search().list(
                part='snippet',
                q=username,
                type='channel',
                maxResults=1
            )
            response = request.execute()
            
            # Verify the channel handle matches
            for item in response['items']:
                channel_id = item['snippet']['channelId']
                channel_info = self.youtube.channels().list(
                    part='snippet',
                    id=channel_id
                ).execute()
                
                if channel_info['items'][0]['snippet'].get('customUrl', '').lower() == f'@{username.lower()}':
                    return channel_id
            
            raise ValueError(f"Could not find channel ID for {channel_url}")
    
    # Get channel statistics including subscriber count
    def get_channel_stats(self, channel_id):
        request = self.youtube.channels().list(
            part='statistics,snippet',
            id=channel_id
        )
        response = request.execute()
        channel_info = response['items'][0]
        return {
            'title': channel_info['snippet']['title'],
            'subscribers': int(channel_info['statistics']['subscriberCount']),
            'thumbnail': channel_info['snippet']['thumbnails']['high']['url']
        }
    
    # í•´ë‹¹ ì±„ë„ì˜ ë™ì˜ìƒ ì •ë³´
    def get_all_videos(self, channel_id):
        videos = []
        next_page_token = None
        
        while True:
            request = self.youtube.search().list(
                part='snippet',
                channelId=channel_id,
                maxResults=50,
                type='video',
                pageToken=next_page_token,
                order='date'  # ìµœì‹  ì˜ìƒë¶€í„°
            )
            response = request.execute()
            
            # Get video IDs for batch statistics request
            video_ids = [item['id']['videoId'] for item in response['items']]
            
            if not video_ids:
                break
            
            # Get video statistics in batch
            stats_request = self.youtube.videos().list(
                part='statistics',
                id=','.join(video_ids)
            )
            stats_response = stats_request.execute()
            
            # Combine video information with statistics
            for video, stats in zip(response['items'], stats_response['items']):
                videos.append({
                    'title': video['snippet']['title'],
                    'thumbnail': video['snippet']['thumbnails']['high']['url'],
                    'views': int(stats['statistics'].get('viewCount', 0)),
                    'like_count': int(stats['statistics'].get('likeCount', 0)),
                    'comment_count': int(stats['statistics'].get('commentCount', 0)),
                    'published_at': video['snippet']['publishedAt'],
                    'video_id': video['id']['videoId']
                })
            
            next_page_token = response.get('nextPageToken')
            if not next_page_token:
                break
        
        return videos
    
    # ìƒìœ„ nê°œ ëŒ“ê¸€
    def get_top_comments(self, video_id, max_results=3):
        """Get top comments for a specific video"""
        try:
            request = self.youtube.commentThreads().list(
                part='snippet',
                videoId=video_id,
                maxResults=max_results,
                order='relevance'  # ì¸ê¸°ìˆœ ì •ë ¬
            )
            response = request.execute()
            
            comments = []
            for item in response.get('items', []):
                comment = item['snippet']['topLevelComment']['snippet']
                comments.append({
                    'author': comment['authorDisplayName'],
                    'text': comment['textDisplay'],
                    'like_count': comment['likeCount'],
                    'published_at': comment['publishedAt']
                })
            
            return comments
        except Exception as e:
            # ëŒ“ê¸€ì´ ë¹„í™œì„±í™”ëœ ê²½ìš° ë“±ì˜ ì˜ˆì™¸ ì²˜ë¦¬
            return [{'author': 'ëŒ“ê¸€ ì—†ìŒ', 'text': 'ëŒ“ê¸€ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ë¹„í™œì„±í™”ë˜ì—ˆê±°ë‚˜ ì ‘ê·¼ ë¶ˆê°€)', 'like_count': 0, 'published_at': ''}]


# ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
def get_info(search_id, table_name):
    conn = connect_postgres()
    cur = conn.cursor()

    cur.execute(f"""
    SELECT 
        keyword, channel_name, video_id, video_title, video_thumbnail, video_view_count, video_like_count, video_comment_count, video_view_subscriber_ratio, is_shorts, comment_1, comment_2, comment_3, transcript
    FROM 
        {table_name} 
    WHERE 
        search_unique_id = %s
    """, (search_id,))

    results = cur.fetchall()

    # í‚¤ì›Œë“œë„ ì¡°íšŒí•´ì•¼
    columns = [
        'í‚¤ì›Œë“œ', 'ì±„ë„ëª…', 'video_id', 'ì œëª©', 'ì¸ë„¤ì¼', 'ì¡°íšŒìˆ˜', 'ì¢‹ì•„ìš”', 'ëŒ“ê¸€ìˆ˜', 
        'ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨', 'ì‡¼ì¸ ', 'ëŒ“ê¸€1', 'ëŒ“ê¸€2', 'ëŒ“ê¸€3', 'ìŠ¤í¬ë¦½íŠ¸'
    ]
    
    df = pd.DataFrame(results, columns=columns)
    
    cur.close()
    conn.close()
    
    return df

# í‚¤ì›Œë“œë¡œ ë™ì˜ìƒ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
def fetch_youtube_data(search_query, max_results=50):
    youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)
    
    videos_data = []
    request = youtube.search().list(
        q=search_query,
        part='snippet',
        type='video',
        maxResults=min(50, max_results)
    )
    
    response = request.execute()
    video_ids = [item['id']['videoId'] for item in response['items']]
    stats_request = youtube.videos().list(
        part='statistics',
        id=','.join(video_ids)
    )
    stats_response = stats_request.execute()
    channel_ids = [item['snippet']['channelId'] for item in response['items']]
    channels_request = youtube.channels().list(
        part='statistics',
        id=','.join(set(channel_ids))
    )
    channels_response = channels_request.execute()
    
    channel_subscribers = {
        channel['id']: int(channel['statistics'].get('subscriberCount', 0))
        for channel in channels_response['items']
    }
    
    for video, stats in zip(response['items'], stats_response['items']):
        views = int(stats['statistics'].get('viewCount', 0))
        if views >= 1000:
            video_id = video['id']['videoId']
            channel_id = video['snippet']['channelId']
            subscriber_count = channel_subscribers.get(channel_id, 0)
            view_sub_ratio = (views / subscriber_count) * 100 if subscriber_count > 0 else 0
            script = youtube_transcript(video_id)
            is_shorts = is_youtubeshorts(video_id)
            videos_data.append({
                'title': video['snippet']['title'], 
                'channel': video['snippet']['channelTitle'], 
                'publishedAt': video['snippet']['publishedAt'], 
                'views': views, 
                'subscribers': subscriber_count, 
                'view_sub_ratio': round(view_sub_ratio, 2),
                'likes': int(stats['statistics'].get('likeCount', 0)), 
                'comments': int(stats['statistics'].get('commentCount', 0)), 
                'description': video['snippet']['description'], 
                'url': f"https://www.youtube.com/watch?v={video_id}", 
                'thumbnail': video['snippet']['thumbnails']['high']['url'], 
                '1min_script': script,
                'is_shorts': is_shorts
            })
    
    return pd.DataFrame(videos_data)

# ë¶„ì„ ê²°ê³¼ ì €ì¥ í•¨ìˆ˜
def save_video_analysis(table_name, search_unique_id, is_shorts, analysis_result):
    conn = connect_postgres()
    cur = conn.cursor()
    
    cur.execute(f"""
        INSERT INTO {table_name} (search_unique_id, is_shorts, llm_analysis) VALUES (%s, %s, %s)
        """,  # channel_analysis
        (search_unique_id, is_shorts, analysis_result)
    )
    
    conn.commit()
    cur.close()
    conn.close()

# ê° search_unique_idë³„ë¡œ ê°€ì¥ ë†’ì€ ë¹„ìœ¨ì˜ ë™ì˜ìƒ í•˜ë‚˜ì”© ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_top_videos_by_search_id(table_name):
    conn = connect_postgres()
    cur = conn.cursor()

    # ëª¨ë“  ê³ ìœ  search_unique_id ê°€ì ¸ì˜¤ê¸°
    cur.execute(f"SELECT DISTINCT search_unique_id FROM {table_name} ORDER BY search_unique_id DESC")
    search_ids = [row[0] for row in cur.fetchall()]
    
    # ê²°ê³¼ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    results = []
    
    # ê° search_unique_idì— ëŒ€í•´ ê°€ì¥ ë†’ì€ video_view_subscriber_ratioë¥¼ ê°€ì§„ ë™ì˜ìƒ ê°€ì ¸ì˜¤ê¸°
    for search_id in search_ids:
        cur.execute(f"""
        SELECT 
            search_unique_id, keyword, channel_name, video_id, video_title, video_thumbnail, 
            video_view_count, video_like_count, video_comment_count, video_view_subscriber_ratio, 
            is_shorts, comment_1, comment_2, comment_3, transcript
        FROM 
            {table_name} 
        WHERE 
            search_unique_id = %s
        ORDER BY 
            video_view_subscriber_ratio DESC
        LIMIT 1
        """, (search_id,))
        
        row = cur.fetchone()
        if row:
            results.append(row)
    
    # ì»¬ëŸ¼ ì´ë¦„
    columns = [
        'pk_ID', 'í‚¤ì›Œë“œ', 'ì±„ë„ëª…', 'video_id', 'ì œëª©', 'ì¸ë„¤ì¼', 
        'ì¡°íšŒìˆ˜', 'ì¢‹ì•„ìš”', 'ëŒ“ê¸€ìˆ˜', 'ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨', 
        'ì‡¼ì¸ ', 'ëŒ“ê¸€1', 'ëŒ“ê¸€2', 'ëŒ“ê¸€3', 'ìŠ¤í¬ë¦½íŠ¸'
    ]
    
    df = pd.DataFrame(results, columns=columns)
    
    cur.close()
    conn.close()
    
    return df

def blog_summarizer(client, llm, text):
    try:
        # ì…ë ¥ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ ê²½ìš° ì œí•œ (API ì œí•œì„ ê³ ë ¤)
        if len(text) > 15000:
            text = text[:15000] + "..."
    
        summary = client.chat.completions.create(
            model=llm,  # 'gpt-4o-2024-08-06'
            messages=[
                {"role": "system", "content": "ë‹¤ìŒ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”. í•µì‹¬ ë‚´ìš©ê³¼ ì£¼ìš” í¬ì¸íŠ¸ë¥¼ í¬í•¨ì‹œì¼œì•¼ í•©ë‹ˆë‹¤."},
                {"role": "user", "content": text}
            ],
            temperature=0.3, 
            max_tokens=500,
        )
        
        return summary.choices[0].message.content.strip()
    
    except Exception as e:
        return {"ë¸”ë¡œê·¸ ë‚´ìš© ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.": str(e)}


st.title("ìœ íŠœë¸Œ ì±„ë„ ë¶„ì„ê¸°")
tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
    "ì±„ë„ ë°ì´í„° ìˆ˜ì§‘", "í‚¤ì›Œë“œ ê¸°ë°˜ ë°ì´í„° ìˆ˜ì§‘", 
    "ì±„ë„ ë°ì´í„° ì¡°íšŒ", "í‚¤ì›Œë“œ ë°ì´í„° ì¡°íšŒ", 
    "ë¸”ë¡œê·¸ ë¶„ì„ê¸°", "ë¸”ë¡œê·¸ í†µí•© ë¶„ì„", 
    "ìœ íŠœë¸Œ ì»¨í…ì¸  ë§Œë“¤ê¸°"
])

# íƒ­ 1: ì±„ë„ ë°ì´í„° ìˆ˜ì§‘ íƒ­
with tab1:
    st.subheader("ì±„ë„ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°")
    channel_url = st.text_input("ìœ íŠœë¸Œ ì±„ë„ ì£¼ì†Œ (e.g., https://youtube.com/@channelname)")
    keyword = st.text_input("ë™ì˜ìƒ ì œì‘ì— ì‚¬ìš©í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”")
    submit_button = st.button("ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥", type="primary")

    if submit_button and channel_url and keyword:
        try:
            with st.spinner("ì±„ë„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                analyzer = YouTubeAnalyzer(YOUTUBE_API_KEY)
                
                # ê³ ìœ  ê²€ìƒ‰ ID ìƒì„± (PostgreSQLì—ì„œ ìë™ìœ¼ë¡œ ìƒì„±)
                pk_id = search_unique_id()
                
                # ì±„ë„ ID ê°€ì ¸ì˜¤ê¸°
                channel_id = analyzer.get_channel_id(channel_url)
                
                # ì±„ë„ í†µê³„ ê°€ì ¸ì˜¤ê¸°
                channel_stats = analyzer.get_channel_stats(channel_id)
                
                # ì±„ë„ ì •ë³´ ì¶œë ¥
                st.subheader(f"ì±„ë„: {channel_stats['title']}")
                col1, col2 = st.columns([1, 3])
                with col1:
                    st.image(channel_stats['thumbnail'], width=150)
                with col2:
                    st.write(f"êµ¬ë…ì: {format_to_10k(channel_stats['subscribers'])} ({channel_stats['subscribers']}ëª…)")
                
                # ë™ì˜ìƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                videos = analyzer.get_all_videos(channel_id)
                
                # ìƒìœ„ 10ê°œ ë™ì˜ìƒë§Œ ì²˜ë¦¬ (ë˜ëŠ” ì „ì²´ ë™ì˜ìƒì´ 10ê°œ ë¯¸ë§Œì¸ ê²½ìš°)
                top_videos = videos[:10]
                
                st.subheader(f"ìƒìœ„ {len(top_videos)}ê°œ ë™ì˜ìƒ ë¶„ì„ ë° ì €ì¥ ì¤‘...")
                progress_bar = st.progress(0)
                
                # ê° ë™ì˜ìƒ ì •ë³´ ì²˜ë¦¬ ë° ì €ì¥
                for i, video in enumerate(top_videos):
                    video_id = video['video_id']
                    
                    is_shorts = is_youtubeshorts(video_id)  # ì‡¼ì¸  ì—¬ë¶€ í™•ì¸
                    transcript = youtube_transcript(video_id)  # ìë§‰ ê°€ì ¸ì˜¤ê¸°
                    view_subscriber_ratio = video['views'] / channel_stats['subscribers'] if channel_stats['subscribers'] > 0 else 0  # ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨ ê³„ì‚°
                    comments = analyzer.get_top_comments(video_id, 3)  # ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸°
                    
                    save_info(
                        'channel_info', pk_id, keyword, channel_url, channel_stats['title'], channel_stats['subscribers'], 
                        video_id, video['title'], video['thumbnail'], video['views'], video['like_count'], video['comment_count'], view_subscriber_ratio,
                        is_shorts, transcript, video['published_at'], comments
                    )
                    
                    progress_bar.progress((i + 1) / len(top_videos))  # ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
                
                st.success(f"ì„±ê³µì ìœ¼ë¡œ ì±„ë„ '{channel_stats['title']}'ì˜ ë°ì´í„°ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤!")

        except Exception as e:
            st.error(f"ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    elif submit_button:
        st.warning("ëª¨ë“  í•„ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”: ì±„ë„ URL, í‚¤ì›Œë“œ, ê²€ìƒ‰ ID")

# íƒ­ 2: í‚¤ì›Œë“œ ê¸°ë°˜ ë°ì´í„° ìˆ˜ì§‘ íƒ­
with tab2:
    st.subheader("í‚¤ì›Œë“œë¡œ ìœ íŠœë¸Œ ë™ì˜ìƒ ê²€ìƒ‰í•˜ê¸°")
    
    query = st.text_input("ë¶„ì„í•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
    max_results = st.slider("ë¶„ì„í•  ì˜ìƒ ìˆ˜", 10, 50, 30)
    search_button = st.button("ê²€ìƒ‰ ì‹œì‘", type="primary")

    if query and search_button:
        with st.spinner("ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                # ê²€ìƒ‰ ê³ ìœ  ID ìƒì„±
                pk_id = search_unique_id()

                df = fetch_youtube_data(query, max_results)
                
                st.subheader("ğŸ“Š ê¸°ë³¸ í†µê³„")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ì´ ì¡°íšŒìˆ˜", f"{df['views'].sum():,}")
                with col2:
                    st.metric("í‰ê·  ì¢‹ì•„ìš”", f"{int(df['likes'].mean()):,}")
                with col3:
                    st.metric("í‰ê·  ëŒ“ê¸€", f"{int(df['comments'].mean()):,}")
                
                # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                progress_bar = st.progress(0)
                st.text("ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì¤‘...")
                
                # YouTube API ê°ì²´ ìƒì„± (ëŒ“ê¸€ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•¨)
                analyzer = YouTubeAnalyzer(YOUTUBE_API_KEY)
                
                # ê° ë™ì˜ìƒ ì •ë³´ ì²˜ë¦¬ ë° ì €ì¥
                for i, (_, video) in enumerate(df.iterrows()):
                    video_id = video['url'].split('v=')[1] if 'v=' in video['url'] else video['url'].split('/')[-1]
                    
                    # ëŒ“ê¸€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    comments = analyzer.get_top_comments(video_id, 3)
                    
                    # channel_url ìƒì„± (ì±„ë„ ì´ë¦„ìœ¼ë¡œë¶€í„°)
                    channel_url = f"https://www.youtube.com/channel/{video_id}"
                    
                    # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                    save_info(
                        'keyword_info', pk_id, query, channel_url, video['channel'], video['subscribers'],
                        video_id, video['title'], video['thumbnail'], video['views'], video['likes'], video['comments'], video['view_sub_ratio'],
                        video['is_shorts'], video['1min_script'], video['publishedAt'], comments
                    )
                    
                    # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                    progress_bar.progress((i + 1) / len(df))
                
                st.success(f"ì„±ê³µì ìœ¼ë¡œ í‚¤ì›Œë“œ '{query}'ì— ëŒ€í•œ {len(df)}ê°œì˜ ë™ì˜ìƒ ë°ì´í„°ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤! (ê²€ìƒ‰ ID: {pk_id})")
                
                st.subheader("ğŸ”¥ ì¸ê¸° ì˜ìƒ TOP 5")
                top_videos = df.nlargest(5, 'views')
                top_videos['views'] = top_videos['views'].apply(lambda x: format_to_10k(x) + " ê±´")
                top_videos['subscribers'] = top_videos['subscribers'].apply(lambda x: format_to_10k(x) + " ëª…")
                top_videos['view_sub_ratio'] = top_videos['view_sub_ratio'].apply(lambda x: f"{round(x)}%")
                top_videos['thumbnail'] = top_videos.apply(lambda x: f'<a href="{x["url"]}" target="_blank"><img src="{x["thumbnail"]}" width="240"/></a>', axis=1)
                display_videos = top_videos[['thumbnail', 'title', 'channel', 'views', 'subscribers', 'view_sub_ratio', 'is_shorts', '1min_script']]
                display_videos.columns = ['ì¸ë„¤ì¼', 'ì œëª©', 'ì±„ë„ëª…', 'ì¡°íšŒìˆ˜', 'êµ¬ë…ììˆ˜', 'ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨', 'ì‡¼ì¸ ', 'ìµœì´ˆ 3ë¶„ ìŠ¤í¬ë¦½íŠ¸']
                display_videos['ì‡¼ì¸ '] = display_videos['ì‡¼ì¸ '].map({True: 'ì‡¼ì¸ ', False: 'ë¡±í¼'})
                st.markdown(display_videos.to_html(escape=False, index=False), unsafe_allow_html=True)
                
                df['engagement_rate'] = (df['likes'] + df['comments']) / df['views'] * 100
                st.subheader("ğŸ“ˆ ì°¸ì—¬ë„ ë¶„ì„")
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("í‰ê·  ì°¸ì—¬ìœ¨", f"{df['engagement_rate'].mean():.2f}%")
                with col2:
                    st.metric("ìµœê³  ì°¸ì—¬ìœ¨", f"{df['engagement_rate'].max():.2f}%")
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# íƒ­ 3: ì±„ë„ ë°ì´í„° ì¡°íšŒ íƒ­
with tab3:
    st.subheader("ì €ì¥ëœ ì±„ë„ ë°ì´í„° ì¡°íšŒ")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'search_clicked_tab3' not in st.session_state:
        st.session_state.search_clicked_tab3 = False
    if 'shorts_analyzed_tab3' not in st.session_state:
        st.session_state.shorts_analyzed_tab3 = False
    if 'longform_analyzed_tab3' not in st.session_state:
        st.session_state.longform_analyzed_tab3 = False
    if 'shorts_analysis_result_tab3' not in st.session_state:
        st.session_state.shorts_analysis_result_tab3 = None
    if 'longform_analysis_result_tab3' not in st.session_state:
        st.session_state.longform_analysis_result_tab3 = None
    if 'found_data_tab3' not in st.session_state:
        st.session_state.found_data_tab3 = None
    
    # ë¨¼ì € ëª¨ë“  ì±„ë„ë³„ ìµœê³  ì„±ê³¼ ë™ì˜ìƒ í‘œì‹œ
    st.subheader("ê²€ìƒ‰IDë³„ ìµœê³  ì„±ê³¼ ë™ì˜ìƒ ëª©ë¡")
    
    try:
        top_videos_df = get_top_videos_by_search_id('channel_info')
        
        if not top_videos_df.empty:
            # ë°ì´í„° í‘œì‹œ
            st.dataframe(
                top_videos_df,
                column_config={
                    "ì¸ë„¤ì¼": st.column_config.ImageColumn(width="large", help="ì˜ìƒ ì¸ë„¤ì¼"),
                    "ê²€ìƒ‰ID": st.column_config.Column(width="small", help="ì´ IDë¥¼ ì•„ë˜ ì…ë ¥ë€ì— ì…ë ¥í•˜ì—¬ ìƒì„¸ ë¶„ì„"),
                    "í‚¤ì›Œë“œ": st.column_config.Column(width="medium"),
                    "ì±„ë„ëª…": st.column_config.Column(width="medium"), 
                    "ì œëª©": st.column_config.Column(width="large"),
                    "ì¡°íšŒìˆ˜": st.column_config.Column(width="small"),
                    "ì¢‹ì•„ìš”": st.column_config.Column(width="small"),
                    "ëŒ“ê¸€ìˆ˜": st.column_config.Column(width="small"),
                    "ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨": st.column_config.Column(width="small"),
                    "ì‡¼ì¸ ": st.column_config.Column(width="small")
                },
                hide_index=True,
                use_container_width=True,
                height=300
            )
            
            # ID ì„ íƒì— ë„ì›€ì´ ë˜ëŠ” ì •ë³´ ì¶”ê°€
            st.info("ğŸ‘† ìœ„ ëª©ë¡ì—ì„œ ìƒì„¸ ë¶„ì„í•˜ê³  ì‹¶ì€ ê²€ìƒ‰IDë¥¼ í™•ì¸í•˜ê³ , ì•„ë˜ì— ì…ë ¥í•˜ì„¸ìš”.")
        else:
            st.warning("ì €ì¥ëœ ì±„ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error(f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # êµ¬ë¶„ì„  ì¶”ê°€
    st.markdown("---")
    
    # íŠ¹ì • ì±„ë„ ìƒì„¸ ë¶„ì„ ì„¹ì…˜
    st.subheader("íŠ¹ì • ê²€ìƒ‰ID ìƒì„¸ ë¶„ì„")
    search_id_input = st.number_input("ë¶„ì„í•  ê²€ìƒ‰ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”", min_value=1, step=1)
    
    # ê²€ìƒ‰ ë²„íŠ¼ ì½œë°±
    def on_search_click_tab3():
        st.session_state.search_clicked_tab3 = True
        st.session_state.shorts_analyzed_tab3 = False
        st.session_state.longform_analyzed_tab3 = False
        st.session_state.shorts_analysis_result_tab3 = None
        st.session_state.longform_analysis_result_tab3 = None
        st.session_state.found_data_tab3 = None  # ìƒˆ ê²€ìƒ‰ ì‹œ ë°ì´í„° ì´ˆê¸°í™”
        
    # ì‡¼ì¸  ë¶„ì„ ë²„íŠ¼ ì½œë°±
    def on_analyze_shorts_click_tab3():
        st.session_state.shorts_analyzed_tab3 = True
    
    # ë¡±í¼ ë¶„ì„ ë²„íŠ¼ ì½œë°±
    def on_analyze_longform_click_tab3():
        st.session_state.longform_analyzed_tab3 = True
    
    search_button = st.button("ê²€ìƒ‰", type="primary", key="search_button_tab3", on_click=on_search_click_tab3)
    
    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
    if st.session_state.search_clicked_tab3:
        try:
            if 'found_data_tab3' not in st.session_state or st.session_state.found_data_tab3 is None:
                display_df = get_info(search_id_input, 'channel_info')
                st.session_state.found_data_tab3 = display_df
            else:
                display_df = st.session_state.found_data_tab3
            
            if not display_df.empty:
                st.success(f"ê²€ìƒ‰ ID {search_id_input}ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                
                # ì‡¼ì¸ ì™€ ë¡±í¼ ì˜ìƒ ë¶„ë¦¬í•´ì„œ í†µê³„ í‘œì‹œ
                shorts_df = display_df[display_df['ì‡¼ì¸ '] == True]
                longform_df = display_df[display_df['ì‡¼ì¸ '] == False]
                
                col1, col2 = st.columns(2)
                with col1:
                    st.subheader("ì‡¼ì¸  ì˜ìƒ")
                    st.write(f"ì˜ìƒ ìˆ˜: {len(shorts_df)}")
                    if not shorts_df.empty:
                        st.write(f"í‰ê·  ì¡°íšŒìˆ˜: {shorts_df['ì¡°íšŒìˆ˜'].mean():.1f}")
                        st.write(f"í‰ê·  ì¢‹ì•„ìš”: {shorts_df['ì¢‹ì•„ìš”'].mean():.1f}")
                
                with col2:
                    st.subheader("ë¡±í¼ ì˜ìƒ")
                    st.write(f"ì˜ìƒ ìˆ˜: {len(longform_df)}")
                    if not longform_df.empty:
                        st.write(f"í‰ê·  ì¡°íšŒìˆ˜: {longform_df['ì¡°íšŒìˆ˜'].mean():.1f}")
                        st.write(f"í‰ê·  ì¢‹ì•„ìš”: {longform_df['ì¢‹ì•„ìš”'].mean():.1f}")
                
                # ì „ì²´ ë°ì´í„° í‘œì‹œ
                st.subheader("ëª¨ë“  ì˜ìƒ ë°ì´í„°")
                st.dataframe(
                    display_df,
                    column_config={
                        "ì¸ë„¤ì¼": st.column_config.ImageColumn(width="large", help="ì˜ìƒ ì¸ë„¤ì¼"),
                        "ì±„ë„ëª…": st.column_config.Column(width="medium"), 
                        "ì œëª©": st.column_config.Column(width="large"),
                        "ì¡°íšŒìˆ˜": st.column_config.Column(width="small"),
                        "ì¢‹ì•„ìš”": st.column_config.Column(width="small"),
                        "ëŒ“ê¸€ìˆ˜": st.column_config.Column(width="small"),
                        "ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨": st.column_config.Column(width="small"),
                        "ì‡¼ì¸ ": st.column_config.Column(width="small"), 
                        "ëŒ“ê¸€1": st.column_config.Column(width="large"), 
                        "ëŒ“ê¸€2": st.column_config.Column(width="large"), 
                        "ëŒ“ê¸€3": st.column_config.Column(width="large"), 
                        "ìŠ¤í¬ë¦½íŠ¸": st.column_config.TextColumn(width="large")
                    },
                    hide_index=True,
                    use_container_width=True,
                    height=600
                )
                
                # ë¶„ì„ ì„¹ì…˜
                st.subheader("ì±„ë„ ë°ì´í„° ë¶„ì„í•˜ê¸°")
                
                # 1. ì‡¼ì¸  ë¶„ì„ ì„¹ì…˜
                st.write("### ì‡¼ì¸  ì˜ìƒ ë¶„ì„")
                
                if len(shorts_df) == 0:
                    st.info("í•´ë‹¹ ì±„ë„ì—ëŠ” ì‡¼ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # ì‡¼ì¸  ë¶„ì„ ë²„íŠ¼
                    if not st.session_state.shorts_analyzed_tab3:
                        shorts_btn = st.button(
                            "ì‡¼ì¸  ë¶„ì„ ì‹œì‘", 
                            type="primary", 
                            key="btn_analyze_shorts",
                            on_click=on_analyze_shorts_click_tab3
                        )
                    
                    # ë¶„ì„ ìˆ˜í–‰ ë° ê²°ê³¼ í‘œì‹œ
                    if st.session_state.shorts_analyzed_tab3:
                        if st.session_state.shorts_analysis_result_tab3 is None:
                            with st.spinner("ì‡¼ì¸  ì˜ìƒ ë¶„ì„ ì¤‘..."):
                                # ì‡¼ì¸  ë¶„ì„ ìˆ˜í–‰
                                shorts_analysis = analyze_channel_video(openai_client, llm_option, display_df, is_shorts=True)
                                st.session_state.shorts_analysis_result_tab3 = shorts_analysis
                                
                                # ë¶„ì„ ë‚´ìš© ì €ì¥
                                save_video_analysis('channel_analysis', search_id_input, True, shorts_analysis)
                                
                                st.success("ì‡¼ì¸  ì˜ìƒ ë¶„ì„ ì™„ë£Œ ë° ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        
                        # ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                        st.write(st.session_state.shorts_analysis_result_tab3)
                
                # êµ¬ë¶„ì„ 
                st.markdown("---")
                
                # 2. ë¡±í¼ ë¶„ì„ ì„¹ì…˜
                st.write("### ë¡±í¼ ì˜ìƒ ë¶„ì„")
                
                if len(longform_df) == 0:
                    st.info("í•´ë‹¹ ì±„ë„ì—ëŠ” ë¡±í¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # ë¡±í¼ ë¶„ì„ ë²„íŠ¼
                    if not st.session_state.longform_analyzed_tab3:
                        longform_btn = st.button(
                            "ë¡±í¼ ë¶„ì„ ì‹œì‘", 
                            type="primary", 
                            key="btn_analyze_longform",
                            on_click=on_analyze_longform_click_tab3
                        )
                    
                    # ë¶„ì„ ìˆ˜í–‰ ë° ê²°ê³¼ í‘œì‹œ
                    if st.session_state.longform_analyzed_tab3:
                        if st.session_state.longform_analysis_result_tab3 is None:
                            with st.spinner("ë¡±í¼ ì˜ìƒ ë¶„ì„ ì¤‘..."):
                                # ë¡±í¼ ë¶„ì„ ìˆ˜í–‰
                                longform_analysis = analyze_channel_video(openai_client, llm_option, display_df, is_shorts=True)
                                st.session_state.longform_analysis_result_tab3 = longform_analysis
                                
                                # ë¶„ì„ ë‚´ìš© ì €ì¥
                                save_video_analysis('channel_analysis', search_id_input, False, longform_analysis)
                                
                                st.success("ë¡±í¼ ì˜ìƒ ë¶„ì„ ì™„ë£Œ ë° ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        
                        # ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                        st.write(st.session_state.longform_analysis_result_tab3)   
            else:
                st.warning(f"ê²€ìƒ‰ ID {search_id_input}ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                st.session_state.found_data_tab3 = None
        except Exception as e:
            st.error(f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.session_state.found_data_tab3 = None

# íƒ­ 4: í‚¤ì›Œë“œ ë°ì´í„° ì¡°íšŒ íƒ­
with tab4:
    st.subheader("ì €ì¥ëœ í‚¤ì›Œë“œ ë°ì´í„° ì¡°íšŒ")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'search_clicked_tab4' not in st.session_state:
        st.session_state.search_clicked_tab4 = False
    if 'shorts_analyzed_tab4' not in st.session_state:  # ì‡¼ì¸  ë¶„ì„ ì™„ë£Œ ì—¬ë¶€
        st.session_state.shorts_analyzed_tab4 = False
    if 'longform_analyzed_tab4' not in st.session_state:  # ë¡±í¼ ë¶„ì„ ì™„ë£Œ ì—¬ë¶€
        st.session_state.longform_analyzed_tab4 = False
    if 'shorts_analysis_result_tab4' not in st.session_state:  # ì‡¼ì¸  ë¶„ì„ ê²°ê³¼
        st.session_state.shorts_analysis_result_tab4 = None
    if 'longform_analysis_result_tab4' not in st.session_state:  # ë¡±í¼ ë¶„ì„ ê²°ê³¼
        st.session_state.longform_analysis_result_tab4 = None
    if 'found_data_tab4' not in st.session_state:
        st.session_state.found_data_tab4 = None
    
    # ë¨¼ì € ëª¨ë“  ì±„ë„ë³„ ìµœê³  ì„±ê³¼ ë™ì˜ìƒ í‘œì‹œ
    st.subheader("ê²€ìƒ‰IDë³„ ìµœê³  ì„±ê³¼ ë™ì˜ìƒ ëª©ë¡")
    
    try:
        top_videos_df = get_top_videos_by_search_id('keyword_info')
        
        if not top_videos_df.empty:
            # ë°ì´í„° í‘œì‹œ
            st.dataframe(
                top_videos_df,
                column_config={
                    "ì¸ë„¤ì¼": st.column_config.ImageColumn(width="large", help="ì˜ìƒ ì¸ë„¤ì¼"),
                    "ê²€ìƒ‰ID": st.column_config.Column(width="small", help="ì´ IDë¥¼ ì•„ë˜ ì…ë ¥ë€ì— ì…ë ¥í•˜ì—¬ ìƒì„¸ ë¶„ì„"),
                    "í‚¤ì›Œë“œ": st.column_config.Column(width="medium"),
                    "ì±„ë„ëª…": st.column_config.Column(width="medium"), 
                    "ì œëª©": st.column_config.Column(width="large"),
                    "ì¡°íšŒìˆ˜": st.column_config.Column(width="small"),
                    "ì¢‹ì•„ìš”": st.column_config.Column(width="small"),
                    "ëŒ“ê¸€ìˆ˜": st.column_config.Column(width="small"),
                    "ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨": st.column_config.Column(width="small"),
                    "ì‡¼ì¸ ": st.column_config.Column(width="small")
                },
                hide_index=True,
                use_container_width=True,
                height=300
            )
            
            # ID ì„ íƒì— ë„ì›€ì´ ë˜ëŠ” ì •ë³´ ì¶”ê°€
            st.info("ğŸ‘† ìœ„ ëª©ë¡ì—ì„œ ìƒì„¸ ë¶„ì„í•˜ê³  ì‹¶ì€ ê²€ìƒ‰IDë¥¼ í™•ì¸í•˜ê³ , ì•„ë˜ì— ì…ë ¥í•˜ì„¸ìš”.")
        else:
            st.warning("ì €ì¥ëœ ì±„ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error(f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # êµ¬ë¶„ì„  ì¶”ê°€
    st.markdown("---")
    
    # íŠ¹ì • ì±„ë„ ìƒì„¸ ë¶„ì„ ì„¹ì…˜
    st.subheader("íŠ¹ì • ê²€ìƒ‰ID ìƒì„¸ ë¶„ì„")
    search_id_input = st.number_input("í‚¤ì›Œë“œì— ëŒ€í•´ ì¡°íšŒí•  ê²€ìƒ‰ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”", min_value=1, step=1)
    
    # ê²€ìƒ‰ ë²„íŠ¼ ì½œë°±
    def on_search_click_tab4():
        st.session_state.search_clicked_tab4 = True
        st.session_state.shorts_analyzed_tab4 = False
        st.session_state.longform_analyzed_tab4 = False
        st.session_state.shorts_analysis_result_tab4 = None
        st.session_state.longform_analysis_result_tab4 = None
        st.session_state.found_data_tab4 = None  # ìƒˆ ê²€ìƒ‰ ì‹œ ë°ì´í„° ì´ˆê¸°í™”
        
    # ì‡¼ì¸  ë¶„ì„ ë²„íŠ¼ ì½œë°±
    def on_analyze_shorts_click_tab4():
        st.session_state.shorts_analyzed_tab4 = True
    
    # ë¡±í¼ ë¶„ì„ ë²„íŠ¼ ì½œë°±
    def on_analyze_longform_click_tab4():
        st.session_state.longform_analyzed_tab4 = True
    
    search_button_keyword = st.button("ê²€ìƒ‰", type="primary", key="search_button_keyword_tab4", on_click=on_search_click_tab4)
    
    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
    if st.session_state.search_clicked_tab4:
        try:
            if 'found_data_tab4' not in st.session_state or st.session_state.found_data_tab4 is None:
                display_df = get_info(search_id_input, 'keyword_info')
                st.session_state.found_data_tab4 = display_df
            else:
                display_df = st.session_state.found_data_tab4
            
            if not display_df.empty:
                st.success(f"ê²€ìƒ‰ ID {search_id_input}ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                
                # ì‡¼ì¸ ì™€ ë¡±í¼ ì˜ìƒ ë¶„ë¦¬í•´ì„œ í†µê³„ í‘œì‹œ
                shorts_df = display_df[display_df['ì‡¼ì¸ '] == True]
                longform_df = display_df[display_df['ì‡¼ì¸ '] == False]
                
                col1, col2 = st.columns(2)
                with col1:
                    st.subheader("ì‡¼ì¸  ì˜ìƒ")
                    st.write(f"ì˜ìƒ ìˆ˜: {len(shorts_df)}")
                    if not shorts_df.empty:
                        st.write(f"í‰ê·  ì¡°íšŒìˆ˜: {shorts_df['ì¡°íšŒìˆ˜'].mean():.1f}")
                        st.write(f"í‰ê·  ì¢‹ì•„ìš”: {shorts_df['ì¢‹ì•„ìš”'].mean():.1f}")
                
                with col2:
                    st.subheader("ë¡±í¼ ì˜ìƒ")
                    st.write(f"ì˜ìƒ ìˆ˜: {len(longform_df)}")
                    if not longform_df.empty:
                        st.write(f"í‰ê·  ì¡°íšŒìˆ˜: {longform_df['ì¡°íšŒìˆ˜'].mean():.1f}")
                        st.write(f"í‰ê·  ì¢‹ì•„ìš”: {longform_df['ì¢‹ì•„ìš”'].mean():.1f}")
                
                # ì „ì²´ ë°ì´í„° í‘œì‹œ
                st.subheader("ëª¨ë“  ì˜ìƒ ë°ì´í„°")
                # st.dataframe(display_df, use_container_width=True)
                st.dataframe(
                    display_df,
                    column_config={
                        "ì¸ë„¤ì¼": st.column_config.ImageColumn(width="large", help="ì˜ìƒ ì¸ë„¤ì¼"),
                        "ì±„ë„ëª…": st.column_config.Column(width="medium"), 
                        "ì œëª©": st.column_config.Column(width="large"),
                        "ì¡°íšŒìˆ˜": st.column_config.Column(width="small"),
                        "ì¢‹ì•„ìš”": st.column_config.Column(width="small"),
                        "ëŒ“ê¸€ ìˆ˜": st.column_config.Column(width="small"),
                        "ì¡°íšŒìˆ˜/êµ¬ë…ì ë¹„ìœ¨": st.column_config.Column(width="small"),
                        "ì‡¼ì¸ ": st.column_config.Column(width="small"), 
                        "ëŒ“ê¸€1": st.column_config.Column(width="large"), 
                        "ëŒ“ê¸€2": st.column_config.Column(width="large"), 
                        "ëŒ“ê¸€3": st.column_config.Column(width="large"), 
                        "ìŠ¤í¬ë¦½íŠ¸": st.column_config.TextColumn(width="large")
                    },
                    hide_index=True,
                    use_container_width=True,
                    height=600
                )
                
                # ë¶„ì„ ì„¹ì…˜
                st.subheader("ì±„ë„ ë°ì´í„° ë¶„ì„í•˜ê¸°")
                
                # 1. ì‡¼ì¸  ë¶„ì„ ì„¹ì…˜
                st.write("### ì‡¼ì¸  ì˜ìƒ ë¶„ì„")
                
                if len(shorts_df) == 0:
                    st.info("í•´ë‹¹ ì±„ë„ì—ëŠ” ì‡¼ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # ì‡¼ì¸  ë¶„ì„ ë²„íŠ¼
                    if not st.session_state.shorts_analyzed_tab4:
                        shorts_btn = st.button(
                            "ì‡¼ì¸  ë¶„ì„ ì‹œì‘", 
                            type="primary", 
                            key="btn_analyze_shorts_tab4",
                            on_click=on_analyze_shorts_click_tab4
                        )
                    
                    # ë¶„ì„ ìˆ˜í–‰ ë° ê²°ê³¼ í‘œì‹œ
                    if st.session_state.shorts_analyzed_tab4:
                        if st.session_state.shorts_analysis_result_tab4 is None:
                            with st.spinner("ì‡¼ì¸  ì˜ìƒ ë¶„ì„ ì¤‘..."):
                                # ì‡¼ì¸  ë¶„ì„ ìˆ˜í–‰
                                shorts_analysis = analyze_keyword_video(openai_client, llm_option, display_df, is_shorts=True)
                                st.session_state.shorts_analysis_result_tab4 = shorts_analysis
                                
                                # ë¶„ì„ ë‚´ìš© ì €ì¥
                                save_video_analysis('keyword_analysis', search_id_input, True, shorts_analysis)
                                
                                st.success("ì‡¼ì¸  ì˜ìƒ ë¶„ì„ ì™„ë£Œ ë° ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        
                        # ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                        st.write(st.session_state.shorts_analysis_result_tab4)
                
                # êµ¬ë¶„ì„ 
                st.markdown("---")
                
                # 2. ë¡±í¼ ë¶„ì„ ì„¹ì…˜
                st.write("### ë¡±í¼ ì˜ìƒ ë¶„ì„")
                
                if len(longform_df) == 0:
                    st.info("í•´ë‹¹ ì±„ë„ì—ëŠ” ë¡±í¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # ë¡±í¼ ë¶„ì„ ë²„íŠ¼
                    if not st.session_state.longform_analyzed_tab4:
                        longform_btn = st.button(
                            "ë¡±í¼ ë¶„ì„ ì‹œì‘", 
                            type="primary", 
                            key="btn_analyze_longform_tab4",
                            on_click=on_analyze_longform_click_tab4
                        )
                    
                    # ë¶„ì„ ìˆ˜í–‰ ë° ê²°ê³¼ í‘œì‹œ
                    if st.session_state.longform_analyzed_tab4:
                        if st.session_state.longform_analysis_result_tab4 is None:
                            with st.spinner("ë¡±í¼ ì˜ìƒ ë¶„ì„ ì¤‘..."):
                                # ë¡±í¼ ë¶„ì„ ìˆ˜í–‰
                                longform_analysis = analyze_keyword_video(openai_client, llm_option, display_df, is_shorts=False)
                                st.session_state.longform_analysis_result_tab4 = longform_analysis
                                
                                # ë¶„ì„ ë‚´ìš© ì €ì¥
                                save_video_analysis('keyword_analysis', search_id_input, False, longform_analysis)
                                
                                st.success("ë¡±í¼ ì˜ìƒ ë¶„ì„ ì™„ë£Œ ë° ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        
                        # ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                        st.write(st.session_state.longform_analysis_result_tab4)  
        
        except Exception as e:
            st.error(f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.session_state.found_data_tab4 = None

# íƒ­ 5: ë¸”ë¡œê·¸ ë¶„ì„ê¸° íƒ­
with tab5:
    st.subheader("ë¸”ë¡œê·¸ ë¶„ì„ê¸°")

    analysis_keyword = st.text_input('ë¸”ë¡œê·¸ ë¶„ì„ì„ ìœ„í•œ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”. ë¶„ì„ ê·¸ë£¹ì˜ ì´ë¦„ì„ ê²°ì •í•©ë‹ˆë‹¤.')
    
    # # ë¸”ë¡œê·¸ í•œê°œ ë¶„ì„
    # blog_url = st.text_input('ë¶„ì„í•  ë¸”ë¡œê·¸ ì£¼ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš”.')  # ë‚˜ì¤‘ì— 10ê°œë¡œ ëŠ˜ë¦´ ì˜ˆì •
    # analyse_button = st.button("ë¸”ë¡œê·¸ ë¶„ì„ ì‹œì‘", type="primary")
    
    # if blog_url and analysis_keyword and analyse_button:
    #     with st.spinner("ë¸”ë¡œê·¸ ë‚´ìš©ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
    #         try:
    #             extracted_data = blog_content(blog_url)

    #             blog_summary = blog_summarizer(openai_client, extracted_data['content'])

    #             conn = connect_postgres()
    #             cur = conn.cursor()

    #             # RETURNING ì ˆ ì¶”ê°€
    #             cur.execute("""
    #             INSERT INTO blog_summary (keyword, url, summary) 
    #             VALUES (%s, %s, %s) RETURNING id
    #             """, (analysis_keyword, blog_url, blog_summary))
                
    #             # ë°˜í™˜ëœ id ê°€ì ¸ì˜¤ê¸°
    #             inserted_id = cur.fetchone()[0]

    #             conn.commit()
    #             cur.close()
    #             conn.close()

    #             st.subheader("ë¸”ë¡œê·¸ ìš”ì•½ ê²°ê³¼")
    #             st.write(blog_summary)
                
    #             st.success(f"ë¸”ë¡œê·¸ ë¶„ì„ ê²°ê³¼ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! (ID: {inserted_id})")
    #         except Exception as e:
    #             st.error(f"ë¸”ë¡œê·¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # # ë¸”ë¡œê·¸ ì—¬ëŸ¬ê°œ ë¶„ì„
    blog_urls_container = st.container()  # ì»¨í…Œì´ë„ˆ ìƒì„±
    
    # ì„¸ì…˜ ìƒíƒœì— URL ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    if 'blog_urls' not in st.session_state:
        st.session_state.blog_urls = [""] * 10  # 10ê°œì˜ ë¹ˆ URLë¡œ ì´ˆê¸°í™”
    
    # 5ê°œì”© ë‘ ì—´ë¡œ ë‚˜ëˆ ì„œ URL ì…ë ¥ í•„ë“œ ìƒì„±
    col1, col2 = st.columns(2)
    
    # ì™¼ìª½ ì»¬ëŸ¼ (0-4ë²ˆ URL)
    with col1:
        for i in range(5):
            st.text_input(
                f"ë¸”ë¡œê·¸ ì£¼ì†Œ {i+1}",
                value=st.session_state.blog_urls[i],
                key=f"blog_url_{i}"
            )
            # ì…ë ¥ í›„ ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            st.session_state.blog_urls[i] = st.session_state[f"blog_url_{i}"]
    
    # ì˜¤ë¥¸ìª½ ì»¬ëŸ¼ (5-9ë²ˆ URL)
    with col2:
        for i in range(5, 10):
            st.text_input(
                f"ë¸”ë¡œê·¸ ì£¼ì†Œ {i+1}",
                value=st.session_state.blog_urls[i],
                key=f"blog_url_{i}"
            )
            # ì…ë ¥ í›„ ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            st.session_state.blog_urls[i] = st.session_state[f"blog_url_{i}"]
    
    # ìœ íš¨í•œ URLì˜ ìˆ˜ ê³„ì‚° (ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ URL)
    valid_urls = [url for url in st.session_state.blog_urls if url.strip()]
    
    # ë¶„ì„ ë²„íŠ¼ê³¼ ìƒíƒœ í‘œì‹œ
    analyse_button = st.button("ë¸”ë¡œê·¸ ë¶„ì„ ì‹œì‘", type="primary", disabled=len(valid_urls) == 0 or not analysis_keyword)
    
    # ë¸”ë¡œê·¸ ë¶„ì„ ì‹¤í–‰
    if analysis_keyword and valid_urls and analyse_button:
        results_container = st.container()  # ë¶„ì„ ê²°ê³¼ ì €ì¥ìš© ì»¨í…Œì´ë„ˆ

        progress_bar = st.progress(0)  # ì§„í–‰ ìƒí™© í‘œì‹œ
        
        # ì„±ê³µ ë° ì‹¤íŒ¨ ê²°ê³¼ ìˆ˜ì§‘
        success_count = 0
        failed_urls = []
        saved_ids = []
        
        # ê° URL ì²˜ë¦¬
        for i, url in enumerate(valid_urls):
            try:
                with st.spinner(f"ë¸”ë¡œê·¸ ë¶„ì„ ì¤‘... ({i+1}/{len(valid_urls)})"):
                    extracted_data = blog_content(url)  # ë¸”ë¡œê·¸ ë‚´ìš© ì¶”ì¶œ
                    
                    blog_summary = blog_summarizer(openai_client, llm_option, extracted_data['content'])  # ë¸”ë¡œê·¸ ìš”ì•½
                    
                    # DBì— ì €ì¥
                    conn = connect_postgres()
                    cur = conn.cursor()
                    
                    cur.execute("""INSERT INTO blog_summary (keyword, url, summary) VALUES (%s, %s, %s) RETURNING id""", (analysis_keyword, url, blog_summary))
                    
                    inserted_id = cur.fetchone()[0]
                    saved_ids.append(inserted_id)
                    
                    conn.commit()
                    cur.close()
                    conn.close()
                    
                    # ì„±ê³µ ì¹´ìš´íŠ¸ ì¦ê°€
                    success_count += 1
                
            except Exception as e:
                # ì‹¤íŒ¨í•œ URL ê¸°ë¡
                failed_urls.append((url, str(e)))
                
                # ì—ëŸ¬ ë°œìƒ ì‹œ DB ì—°ê²° ë‹«ê¸°
                try:
                    if 'conn' in locals() and conn:
                        conn.rollback()
                        cur.close()
                        conn.close()
                except:
                    pass
            
            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            progress_bar.progress((i + 1) / len(valid_urls))
        
        # ë¶„ì„ ì™„ë£Œ í›„ ê²°ê³¼ í‘œì‹œ
        with results_container:
            st.subheader("ë¸”ë¡œê·¸ ë¶„ì„ ê²°ê³¼")
            
            if success_count > 0:
                st.success(f"{success_count}ê°œì˜ ë¸”ë¡œê·¸ê°€ ì„±ê³µì ìœ¼ë¡œ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                # ì €ì¥ëœ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                conn = connect_postgres()
                cur = conn.cursor()
                
                # IN êµ¬ë¬¸ì„ ìœ„í•œ ë¬¸ìì—´ ìƒì„±
                ids_str = ",".join(str(id) for id in saved_ids)
                
                if ids_str:
                    cur.execute(f"""SELECT id, url, summary FROM blog_summary WHERE id IN ({ids_str}) ORDER BY id""")
                    results = cur.fetchall()
                    
                    cur.close()
                    conn.close()
                    
                    # ê²°ê³¼ í‘œì‹œ
                    for result in results:
                        with st.expander(f"ë¸”ë¡œê·¸: {result[1]}"):
                            st.markdown(f"**ID**: {result[0]}")
                            st.markdown("**ìš”ì•½**:")
                            st.write(result[2])
            
            # ì‹¤íŒ¨í•œ URL í‘œì‹œ
            if failed_urls:
                st.error(f"{len(failed_urls)}ê°œì˜ ë¸”ë¡œê·¸ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                for url, error in failed_urls:
                    with st.expander(f"ì‹¤íŒ¨í•œ URL: {url}"):
                        st.error(f"ì˜¤ë¥˜: {error}")
   
# íƒ­ 6: ë¸”ë¡œê·¸ í†µí•© ë¶„ì„ íƒ­
with tab6:
    st.subheader("ë¸”ë¡œê·¸ í†µí•© ë¶„ì„")

    load_keyword = st.text_input('í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”. í•´ë‹¹ í‚¤ì›Œë“œë¡œ ê·¸ë£¨í•‘ëœ ë¸”ë¡œê·¸ ë‚´ìš©ë“¤ì„ í†µí•© ë¶„ì„í•©ë‹ˆë‹¤.')
    int_analyse_button = st.button("í†µí•© ë¶„ì„ ì‹œì‘", type="primary")  # integrated analysis
    
    if load_keyword and int_analyse_button:
        with st.spinner(f"í‚¤ì›Œë“œ '{load_keyword}'ë¡œ ì €ì¥ëœ ë¸”ë¡œê·¸ ìš”ì•½ì„ í†µí•© ë¶„ì„ ì¤‘..."):
            try:
                # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í•´ë‹¹ í‚¤ì›Œë“œë¡œ ì €ì¥ëœ ìš”ì•½ ì¡°íšŒ
                conn = connect_postgres()
                cur = conn.cursor()
                
                cur.execute("""
                SELECT summary FROM blog_summary 
                WHERE keyword = %s
                """, (load_keyword,))
                
                summaries = [row[0] for row in cur.fetchall()]
                
                # ì¡°íšŒëœ ìš”ì•½ì´ ì—†ëŠ” ê²½ìš°
                if not summaries:
                    st.error(f"í‚¤ì›Œë“œ '{load_keyword}'ë¡œ ì €ì¥ëœ ë¸”ë¡œê·¸ ìš”ì•½ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # í†µí•© ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì‘ì„±
                    prompt = f"""
ë‹¤ìŒì€ "{load_keyword}" í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ {len(summaries)}ê°œì˜ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìš”ì•½ì…ë‹ˆë‹¤:

"""
                    for i, summary in enumerate(summaries):
                        prompt += f"\n--- ë¸”ë¡œê·¸ {i+1} ---\n{summary}\n"
                    
                    prompt += f"""
ìœ„ì˜ ë¸”ë¡œê·¸ ìš”ì•½ë“¤ì„ í†µí•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬, ë‹¤ìŒ ì‚¬í•­ì„ í¬í•¨í•œ í¬ê´„ì ì¸ ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

1. ì£¼ìš” ë‚´ìš© ë° ê³µí†µ ì£¼ì œ
2. ì¤‘ìš”í•œ ì‚¬ì‹¤ì´ë‚˜ ì •ë³´
3. ì„œë¡œ ë‹¤ë¥¸ ê´€ì ì´ë‚˜ ì˜ê²¬ (ìˆëŠ” ê²½ìš°)
4. ê´€ë ¨ ì´ë²¤íŠ¸ë‚˜ ì¼ì • (ìˆëŠ” ê²½ìš°)
5. ì „ì²´ ë‚´ìš©ì„ ì¢…í•©í•œ í†µì°°

"{load_keyword}" í‚¤ì›Œë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì´ ëª¨ë“  ë¸”ë¡œê·¸ ë‚´ìš©ì„ ì˜ í†µí•©í•´ì„œ ìš”ì•½í•´ì£¼ì„¸ìš”.
"""
                    
                    # OpenAI APIë¥¼ í†µí•œ í†µí•© ë¶„ì„
                    response = openai_client.chat.completions.create(
                        model=llm_option, 
                        messages=[
                            {"role": "system", "content": "ë‹¹ì‹ ì€ ì—¬ëŸ¬ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì˜ ìš”ì•½ì„ í†µí•©í•˜ì—¬ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.3,
                        max_tokens=1500
                    )
                    
                    integrated_summary = response.choices[0].message.content.strip()
                    
                    # ê³ ìœ  ID ìƒì„±
                    search_id = search_unique_id()
                    
                    # í†µí•© ë¶„ì„ ê²°ê³¼ ì €ì¥
                    cur.execute("""
                    INSERT INTO blog_int_summary (search_unique_id, keyword, int_summary)
                    VALUES (%s, %s, %s)
                    """, (search_id, load_keyword, integrated_summary))
                    
                    conn.commit()
                    
                    # ì„±ê³µ ë©”ì‹œì§€ í‘œì‹œ
                    st.success(f"{len(summaries)}ê°œì˜ ë¸”ë¡œê·¸ ìš”ì•½ì´ ì„±ê³µì ìœ¼ë¡œ í†µí•© ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    
                    # ê²°ê³¼ í‘œì‹œ
                    st.subheader("í†µí•© ë¶„ì„ ê²°ê³¼")
                    st.write(integrated_summary)
                
                cur.close()
                conn.close()
                
            except Exception as e:
                st.error(f"í†µí•© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                # ì—ëŸ¬ ë°œìƒ ì‹œ ì—°ê²° ë‹«ê¸°
                try:
                    if 'conn' in locals() and conn:
                        conn.rollback()
                        cur.close()
                        conn.close()
                except:
                    pass
        
# íƒ­ 7: ìœ íŠœë¸Œ ì½˜í…ì¸  ìƒì„±í•˜ê¸° íƒ­
with tab7:
    st.subheader("ìœ íŠœë¸Œ ì½˜í…ì¸  ìƒì„±í•˜ê¸°")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'content_generated' not in st.session_state:
        st.session_state.content_generated = False

    blog_id = st.text_input('ì£¼ì œë¡œ ì‚¼ì„ ë¸”ë¡œê·¸ ìš”ì•½ë³¸ì˜ ë¶„ì„ ì•„ì´ë””ë¥¼ ì…ë ¥í•˜ì„¸ìš”.')
    
    try:
        conn = connect_postgres()
        cur = conn.cursor()
        
        # ëª¨ë“  í†µí•© ë¸”ë¡œê·¸ ë¶„ì„ ë°ì´í„° ì¡°íšŒ
        cur.execute("""SELECT search_unique_id, keyword FROM blog_int_summary""")
        
        blog_summaries = cur.fetchall()
        cur.close()
        conn.close()
        
        # ë°ì´í„° í‘œì‹œ
        if blog_summaries:
            st.subheader("ì°¸ê³  ê°€ëŠ¥í•œ ë¸”ë¡œê·¸ í†µí•© ë¶„ì„ ë‚´ìš©")
            
            # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
            df = pd.DataFrame(blog_summaries, columns=['ë¶„ì„ID', 'í‚¤ì›Œë“œ'])
            
            # ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
            st.dataframe(
                df,
                column_config={
                    "ë¶„ì„ID": st.column_config.Column(width="small"),
                    "í‚¤ì›Œë“œ": st.column_config.Column(width="medium"),
                },
                hide_index=True,
                use_container_width=True
            )
            
            # í†µí•© ë¶„ì„ ë‚´ìš© ë³´ê¸° ì„¹ì…˜
            selected_id = st.selectbox(
                "ìƒì„¸ ë‚´ìš©ì„ í™•ì¸í•  ë¸”ë¡œê·¸ ë¶„ì„ IDë¥¼ ì„ íƒí•˜ì„¸ìš”:",
                options=[row[0] for row in blog_summaries],
                format_func=lambda x: f"ID: {x} - í‚¤ì›Œë“œ: {df[df['ë¶„ì„ID']==x]['í‚¤ì›Œë“œ'].values[0]}"
            )
            
            if selected_id:
                # ì„ íƒí•œ IDì˜ í†µí•© ë¶„ì„ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
                conn = connect_postgres()
                cur = conn.cursor()
                cur.execute("""SELECT int_summary FROM blog_int_summary WHERE search_unique_id = %s""", (selected_id,))
                
                summary_result = cur.fetchone()
                cur.close()
                conn.close()
                
                if summary_result:
                    with st.expander("ë¸”ë¡œê·¸ í†µí•© ë¶„ì„ ë‚´ìš©", expanded=True):
                        st.markdown(summary_result[0])
        else:
            st.info("ì €ì¥ëœ ë¸”ë¡œê·¸ í†µí•© ë¶„ì„ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    except Exception as e:
        st.error(f"ë¸”ë¡œê·¸ í†µí•© ë¶„ì„ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # êµ¬ë¶„ì„ 
    st.markdown("---")
    
    # ì½˜í…ì¸  ìƒì„± ë²„íŠ¼
    button = st.button("ì½˜í…ì¸  ì œì‘ ì‹œì‘", type="primary")
    
    if button and blog_id:
        with st.spinner('ìœ íŠœë¸Œ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...'):
            try:
                conn = connect_postgres()
                cur = conn.cursor()
                cur.execute("""
                SELECT int_summary, keyword FROM blog_int_summary
                WHERE search_unique_id = %s
                """, (blog_id,))
                
                result = cur.fetchone()
                cur.close()
                conn.close()
                    
                if result:
                    blog_summary = result[0]
                    keyword = result[1]
                else:
                    st.error(f"ID {blog_id}ì— í•´ë‹¹í•˜ëŠ” ë¸”ë¡œê·¸ ë¶„ì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()


                prompt = f"""
ìƒˆë¡œ ë§Œë“¤ ìœ íŠœë¸Œ ë™ì˜ìƒì„ ìœ„í•œ ì œëª©, ì¸ë„¤ì¼ ì´ë¯¸ì§€ ë‚´ìš©, ì²« 2ë¶„ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.

ì œëª© ë° ì¸ë„¤ì¼ ì´ë¯¸ì§€ ë‚´ìš©ì€ ë‹¤ìŒ ì¹´í”¼ë¼ì´íŒ… ë²•ì¹™ 5ê°€ì§€ë¥¼ ê¼­ ì§€ì¼œì„œ ìƒì„±í•´ì£¼ì„¸ìš”:
1. NUMBERS (êµ¬ì²´ì  ìˆ«ì / ì „í›„ ë¹„êµ)
- ì›ë¦¬: ì‚¬ëŒë“¤ì€ êµ¬ì²´ì  ìˆ«ìì™€ ëª…í™•í•œ ê²°ê³¼(Beforeâ†’After)ì— ê°•í•˜ê²Œ ì´ëŒë¦½ë‹ˆë‹¤.
- ì˜ˆì‹œ:
    - â€œ3ê°œì›” ë§Œì— 68â†’46kgâ€
    - â€œ70ëŒ€ ë‡Œë¥¼ 20ëŒ€ ë‡Œë¡œ ë§Œë“¤ì–´ë´¤ë‹¤â€
- ì‹¤ë¬´ íŒ:
    - íš¨ê³¼(ê²°ê³¼)ë‚˜ ê¸°ê°„, ì „í›„ ë¹„êµ ë“±ì„ ë°˜ë“œì‹œ â€˜ìˆ«ìâ€™ë¡œ í‘œê¸°í•˜ë¼.
    - â€œí•˜ë£¨ 10ë¶„ìœ¼ë¡œ -5kgâ€ ë“± ì§§ê³  ì„íŒ©íŠ¸ ìˆê²Œ ê°•ì¡°.

2. ONE & ONLY (í•˜ë‚˜ë§Œ ì§€í‚¤ë©´ ëœë‹¤ / ë‹¨ í•˜ë‚˜ì˜ ë¹„ë°€)
- ì›ë¦¬: â€œì—¬ëŸ¬ ê°œ ì¤‘ í•˜ë‚˜â€ë³´ë‹¤ â€œì˜¤ì§ ì´ í•œ ê°€ì§€â€ê°€ í›¨ì”¬ ë” ì§‘ì¤‘ë„ë¥¼ ë†’ì´ê³  â€˜ê°„ë‹¨íˆ ê°€ëŠ¥í•˜ë‹¤â€™ëŠ” í¬ë§ì„ ì¤ë‹ˆë‹¤.
- ì˜ˆì‹œ:
    - â€œë‚ ì”¬í•œ ì‚¬ëŒë“¤ì˜ ê³µí†µì  1ê°€ì§€â€
    - â€œëª©ìˆ¨ ê±¸ê³  ì§€ì¼œì•¼ í•˜ëŠ” ë‹¨ í•œ ê°€ì§€â€
- ì‹¤ë¬´ íŒ:
    - í•´ê²°ì±…ì„ í•œ ê°€ì§€ì— ì••ì¶•í•´ â€œë‹¨ í•œ ê°€ì§€â€ â€œì˜¤ì§ ì´ê²ƒâ€ â€œí•µì‹¬ 1ê°€ì§€â€ ì‹ìœ¼ë¡œ í¬ì¸íŠ¸ë¥¼ ê°•ì¡°í•œë‹¤.
    - ë„ˆë¬´ ë§ì€ íŒì„ ë‚˜ì—´í•˜ê¸°ë³´ë‹¤, í•µì‹¬ í•œë‘ ê°€ì§€ë§Œ ë½‘ì•„ì£¼ë˜ â€˜ë§ˆì¹˜ ì „ë¶€ì¸ ë“¯â€™ ì–´í•„.

3. SHOCK & HOOK (ì¶©ê²©Â·í˜¸ê¸°ì‹¬ + ì§§ê³  ê°•ë ¬í•œ í‘œí˜„)
- ì›ë¦¬: â€œì´ê±° ë³´ê³ ë„ ì•ˆ ë¹ ì§€ë©´ ì°¾ì•„ì˜¤ë¼â€ì²˜ëŸ¼ ë„ë°œì Â·íŒŒê²©ì  ë¬¸êµ¬ë¡œ ì‹œì²­ìì˜ ì‹œì„ ì„ ê°•í•˜ê²Œ ì¡ì•„ë•ë‹ˆë‹¤.
- ì˜ˆì‹œ:
    - â€œì´ê±° ì•ˆ ë°”ê¾¸ë©´ í‰ìƒ ë‹µë‹µí•©ë‹ˆë‹¤â€
    - â€œì˜·ì¥ â€˜ì´ ì§€ê²½â€™ì´ë©´ ë­˜ í•´ë„ ì„±ê³µ ëª»í•¨â€
- ì‹¤ë¬´ íŒ:
    - ê²½ê³ (ê³µí¬) + í•´ê²°ì±… ì¡°í•©: â€œì´ê±° ì•ˆ í•˜ë©´ ë§í•œë‹¤ â†’ í•˜ì§€ë§Œ ì´ ë°©ë²•ì´ ìˆë‹¤â€
    - ìê·¹ì  í‘œí˜„ì„ ì“°ë˜, ì‹ ë¢°ë¥¼ ìƒì§€ ì•Šë„ë¡ ê³¼ë„í•œ ê³¼ì¥ì€ í”¼í•˜ê³ , ì ì ˆíˆ í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” ìˆ˜ì¤€ìœ¼ë¡œ ì¡°ì ˆ.

4. AUTHORITY (ì „ë¬¸ê°€Â·ìœ ëª…ì¸ ì¸ìš©, ê¶Œìœ„ ë¶€ì—¬)
- ì›ë¦¬: â€œì„¸ê³„ ì„í•™â€ â€œë¸Œë£¨ìŠ¤ ë¦½íŠ¼ ë°•ì‚¬â€ â€œì†Œìœ , ì—„ì •í™”â€ ë“± ê¶Œìœ„ë¥¼ ë¹Œë ¤ì„œ ë¯¿ìŒì„ ì¤€ë‹¤.
- ì˜ˆì‹œ:
    - â€œì„¸ê³„ ì„í•™ë“¤ â€˜ë§¤ì¼ ì´ 5ê°€ì§€ë§Œ ì§€ì¼œë„ 1.5ë°° ë˜‘ë˜‘í•´ì§‘ë‹ˆë‹¤â€™â€
    - â€œì†Œìœ , ì—„ì •í™”ê°€ ì„ íƒí•œ ì €íƒ„ê³ ì§€â€
- ì‹¤ë¬´ íŒ:
    - í†µê³„, ì—°êµ¬ ê²°ê³¼, ìœ ëª…ì¸ì˜ ì‚¬ë¡€ë¥¼ ê°„ê²°í•˜ê²Œ ì–¸ê¸‰í•´ â€œì´ê±´ ê²€ì¦ëœ ì •ë³´â€ë¼ëŠ” ì¸ì‹ì„ ì‹¬ì–´ì¤€ë‹¤.
    - â€œë¯¸êµ­ í•˜ë²„ë“œëŒ€ ì—°êµ¬ì— ë”°ë¥´ë©´â€¦â€ì²˜ëŸ¼ ê°„íŒ(ê¶Œìœ„)ì„ ì „ë©´ì—.

5. URGENCY (ì‹œê¸‰ì„±Â·ì¦‰ì‹œì„±)
- ì›ë¦¬: â€œì•ˆ í•˜ë©´ ì†í•´ ë³¸ë‹¤â€ â€œë¹¨ë¦¬ í•´ì•¼ ê²°ê³¼ê°€ ë‚œë‹¤â€ëŠ” ë©”ì‹œì§€ê°€ í´ë¦­ ë° ì‹œì²­ì„ ë¶€ì¶”ê¹ë‹ˆë‹¤.
- ì˜ˆì‹œ:
    - â€œì—¬ë¦„ ì „ â€˜ì´ê±°ë¶€í„°â€™ ë²„ë¦¬ì„¸ìš”â€
    - â€œì•ˆ ì…ëŠ” ì˜· 7ì¼ ì•ˆì— ë‹¹ì¥ ë²„ë¦¬ì„¸ìš”â€
- ì‹¤ë¬´ íŒ:
    - â€˜ê¸°ê°„/ë§ˆê°â€™ì„ ì„¤ì •í•˜ê±°ë‚˜, â€œì§€ê¸ˆ ë°”ë¡œ ì‹œì‘í•´ì•¼ í•œë‹¤â€ëŠ” ë‰˜ì•™ìŠ¤ë¥¼ ê°•ì¡°.
    - â€œì´ê±¸ ë†“ì¹˜ë©´ ê¸°íšŒê°€ ì‚¬ë¼ì§„ë‹¤â€ëŠ” ì‹¬ë¦¬ì  ì••ë°•ì„ ì‹¬ì–´ì¤Œ.

ì •ë¦¬: â€œìˆ«ì(ê²°ê³¼) + í•˜ë‚˜ë§Œ ì§€í‚¤ë©´ OK + ì¶©ê²©Â·í˜¸ê¸°ì‹¬(ë„ë°œ) + ê¶Œìœ„(ì „ë¬¸ê°€Â·ìœ ëª…ì¸) + ì‹œê¸‰ì„±(ì§€ê¸ˆ í•´ì•¼ í•œë‹¤)â€
ì´ 5ê°€ì§€ë¥¼ ì ì ˆíˆ ì„ì–´ì„œ ì˜ìƒ ì œëª©Â·ì¸ë„¤ì¼ì— ë°°ì¹˜í•˜ë©´, ë†’ì€ í´ë¦­ë¥ (CTR)ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


ì²« 2ë¶„ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒ ê¸€ì“°ê¸° ë²•ì¹™ 4ê°€ì§€ë¥¼ ê¼­ ì§€ì¼œì„œ ì‘ì„±í•´ì£¼ì„¸ìš”:
1. SHORT & SIMPLE (ì§§ê³  ê°„ê²°í•˜ê²Œ, í•µì‹¬ ë¨¼ì €)
- ì›ë¦¬: ê¸¸ê³  ë³µì¡í•œ ê¸€ì€ ì´ˆë°˜ í¥ë¯¸ë¥¼ ë–¨ì–´ëœ¨ë¦½ë‹ˆë‹¤. í•µì‹¬ë¶€í„° ë¹ ë¥´ê²Œ ì œì‹œí•´ ì¤˜ì•¼ í•©ë‹ˆë‹¤.
- ì‹¤ë¬´ íŒ:
    - ê²°ë¡  ë¨¼ì €, ë¶€ì—° ì„¤ëª…ì€ ë’¤ì—
    - ë¬¸ì¥ì„ ìµœëŒ€í•œ ì§§ê²Œ ì“´ë‹¤. (í•œ ë¬¸ì¥ 20~30ì ë‚´ì™¸ ê¶Œì¥)
    - ì—¬ëŸ¬ ë¬¸ì œë¥¼ í•œ ë²ˆì— ì œì‹œí•˜ê¸°ë³´ë‹¤, ê°€ì¥ ì¤‘ìš”í•œ í•œ ê°€ì§€ë¥¼ ë¶€ê°í•˜ì.

2. HOOK & FLOW (í›„í‚¹ â†’ ìì—°ìŠ¤ëŸ¬ìš´ íë¦„)
- ì›ë¦¬: ì²« ë¬¸ì¥ì—ì„œ ë…ìì˜ ì‹œì„ ì„ í™• ì‚¬ë¡œì¡ê³ , ê·¸ ë’¤ ë…¼ë¦¬ì ìœ¼ë¡œ ë‚´ìš©ì„ ì „ê°œí•´ì•¼ ì´íƒˆì„ ë§‰ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì‹¤ë¬´ íŒ:
    - ì²« ë¬¸ì¥: ì¶©ê²©ì  ìˆ˜ì¹˜/ê²½ê³ /ì§ˆë¬¸ ë“±ìœ¼ë¡œ í˜¸ê¸°ì‹¬ì„ ìœ ë°œ.
    - ì´í›„ ë‚´ìš©ì€ ì™œ ì¤‘ìš”í•œê°€ â†’ ì–´ë–»ê²Œ í•´ê²°ë˜ëŠ”ê°€ â†’ ê²°ê³¼/ì‚¬ë¡€ â†’ ê²°ë¡  ìˆœìœ¼ë¡œ íë¦„ ìˆê²Œ ì „ê°œ.

3. YOU-FOCUSED (ë…ì ì¤‘ì‹¬, ë…ìì˜ ì´ìµ ê°•ì¡°)
- ì›ë¦¬: â€œë‚´ê°€ ì™œ ì´ ì •ë³´ë¥¼ ë´ì•¼ í•˜ì§€?â€ë¼ëŠ” ë…ìì˜ ì‹œê°ìœ¼ë¡œ ì‘ì„±í•´ì•¼ ì˜¤ë˜ ì½í™ë‹ˆë‹¤.
- ì‹¤ë¬´ íŒ
    - â€œ~í•˜ì„¸ìš”â€ ëŒ€ì‹  â€œ~í•˜ì‹œë©´, ë‹¹ì‹ ì´ ì–»ê²Œ ë  ì´ìµâ€ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ.
    - â€œë‹¹ì‹ ë„ 2ì£¼ ë§Œì— -3kg ê°€ëŠ¥í•˜ë‹¤ë©´ ì–´ë–¨ê¹Œìš”?â€ì²˜ëŸ¼ ë…ìê°€ ìƒìƒÂ·ê³µê°í•˜ê²Œ ìœ ë„í•œë‹¤.
    - ì „ë¬¸ìš©ì–´ ë‚¨ë°œ X, ì‰¬ìš´ ìš©ì–´ + ì‚¬ë¡€ ì‚¬ìš©.

4. CREDIBILITY & ACTION (ì‹ ë¢°ë„ í™•ë³´ + í–‰ë™ ìœ ë„)
- ì›ë¦¬: ê¸€ì´ ê¸¸ì–´ì§ˆìˆ˜ë¡ â€˜ì§„ì§œì¼ê¹Œ?â€™ë¼ëŠ” ì˜ì‹¬ì´ ìƒê¸¸ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì‹ ë¢°ë¥¼ ìŒ“ê³  ëª…í™•í•œ ë‹¤ìŒ í–‰ë™ì„ ì•ˆë‚´í•´ì•¼ í•©ë‹ˆë‹¤.
- ì‹¤ë¬´ íŒ:
    - ì‹ ë¢° í™•ë³´: í†µê³„, ì—°êµ¬ìë£Œ, ì‹¤ì œ í›„ê¸°, ì „ë¬¸ê°€ ì½”ë©˜íŠ¸ ë“± êµ¬ì²´ì ì¸ íŒ©íŠ¸ë¡œ ë’·ë°›ì¹¨.
    - ë§ˆë¬´ë¦¬: â€œì, ì§€ê¸ˆë¶€í„° 7ì¼ ë™ì•ˆ ì˜·ì¥ ì •ë¦¬ë¥¼ í•´ë³´ì„¸ìš”â€ì²˜ëŸ¼ êµ¬ì²´ì  í–‰ë™ì„ ì œì•ˆ. (CTA)

ë˜í•œ ì´ ë¸”ë¡œê·¸ í†µí•© ìš”ì•½ ë‚´ìš©ë„ ë°˜ì˜í•´ì£¼ì„¸ìš”: {blog_summary}

ìœ„ ì •ë³´ë“¤ì„ í† ëŒ€ë¡œ '{keyword}'ì— ê´€í•œ ë™ì˜ìƒ ì œëª© ë° ì¸ë„¤ì¼ ì´ë¯¸ì§€ ë‚´ìš© ê°ê° 3ê°€ì§€, ìŠ¤í¬ë¦½íŠ¸ í•˜ë‚˜ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ê¼­ ì•„ë˜ í¬ë§·ëŒ€ë¡œ ìƒì„± í•´ì£¼ì„¸ìš”:
[ì œëª©]

[ì¸ë„¤ì¼]

[ìŠ¤í¬ë¦½íŠ¸]

"""
                content = openai_client.chat.completions.create(
                    model=llm_option, 
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹´í”¼ë¼ì´íŒ… ë²•ì¹™ì„ ë”°ë¼ ìˆ˜ì§‘ëœ ë°ì´í„°ì— ê¸°ë°˜í•˜ì—¬ ìœ íŠœë¸Œ ë™ì˜ìƒ ì»¨í…ì¸ ë¥¼ ë§Œë“œëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3,
                    max_tokens=1500
                )
                
                result = content.choices[0].message.content.strip()
                
                # ì„¸ì…˜ ìƒíƒœì— ê²°ê³¼ ì €ì¥ (í™”ë©´ í‘œì‹œìš©)
                st.session_state.generated_content = result
                st.session_state.content_generated = True

                try:
                    parts = result.split("\n\n")
                    
                    title = ""
                    thumbnail = ""
                    script = ""
                        
                    # ê° ë¶€ë¶„ ì¶”ì¶œ
                    for i, part in enumerate(parts):
                        if part.startswith("[ì œëª©]"):  # ì œëª© ë¬¸ìì—´ ì¶”ì¶œ (ì²« ì¤„ì€ [ì œëª©]ì´ë¯€ë¡œ ì œì™¸)
                            title_lines = part.split("\n")[1:]
                            title = "\n".join(title_lines).strip()
                        elif part.startswith("[ì¸ë„¤ì¼]"):  # ì¸ë„¤ì¼ ë¬¸ìì—´ ì¶”ì¶œ (ì²« ì¤„ì€ [ì¸ë„¤ì¼]ì´ë¯€ë¡œ ì œì™¸)
                            thumbnail_lines = part.split("\n")[1:]
                            thumbnail = "\n".join(thumbnail_lines).strip()
                        elif part.startswith("[ìŠ¤í¬ë¦½íŠ¸]"):  # ìŠ¤í¬ë¦½íŠ¸ ë¬¸ìì—´ ì¶”ì¶œ (ì²« ì¤„ì€ [ìŠ¤í¬ë¦½íŠ¸]ì´ë¯€ë¡œ ì œì™¸)
                            script_lines = part.split("\n")[1:]
                            script = "\n".join(script_lines).strip()
                    
                    # ìƒì„±í•œ ìœ íŠœë¸Œ ì»¨í…ì¸  ì •ë³´ë¥¼ DBì— ì €ì¥
                    try:
                        conn = connect_postgres()
                        cur = conn.cursor()
                            
                        # ìƒì„±ëœ ì½˜í…ì¸  ì €ì¥
                        cur.execute("""
                            INSERT INTO youtube_content (id, keyword, title, thumbnail, script)
                            VALUES (%s, %s, %s, %s, %s)
                            """, (blog_id if blog_id else selected_id, keyword, title, thumbnail, script))
                        
                        conn.commit()
                        cur.close()
                        conn.close()
                        
                        st.success("ì½˜í…ì¸ ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ê³  ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

                    except Exception as e:
                        st.error(f"ì½˜í…ì¸  ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                
                except Exception as e:
                    st.error(f"ìƒì„±ëœ ì½˜í…ì¸  íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            
            except Exception as e:
                st.error(f"ì½˜í…ì¸  ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    elif button and not blog_id:
        st.warning("ë¸”ë¡œê·¸ ë¶„ì„ IDë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    # ìƒì„±ëœ ì½˜í…ì¸  í‘œì‹œ
    if st.session_state.get('content_generated', False):
        st.subheader("ìƒì„±ëœ ìœ íŠœë¸Œ ì½˜í…ì¸ ")
        
        # ì œëª© ì„¹ì…˜
        st.markdown("### ğŸ“Œ ì œëª© ì¶”ì²œì²œ")
        if hasattr(st.session_state, 'title'):
            title_options = st.session_state.title.split("\n")
            # ê° ì œëª© ì˜µì…˜ì„ í‘œì‹œ
            for i, title in enumerate(title_options):
                if title.strip():  # ë¹ˆ ì¤„ ë¬´ì‹œ
                    st.markdown(f"**ì˜µì…˜ {i+1}:** {title.strip()}")
        
        # ì¸ë„¤ì¼ ì„¹ì…˜
        st.markdown("### ğŸ–¼ï¸ ì¸ë„¤ì¼ ì´ë¯¸ì§€ì— ë„£ì„ ë‚´ìš© ì¶”ì²œ")
        if hasattr(st.session_state, 'thumbnail'):
            thumbnail_options = st.session_state.thumbnail.split("\n")
            # ê° ì¸ë„¤ì¼ ì˜µì…˜ì„ í‘œì‹œ
            for i, thumbnail in enumerate(thumbnail_options):
                if thumbnail.strip():  # ë¹ˆ ì¤„ ë¬´ì‹œ
                    st.markdown(f"**ì˜µì…˜ {i+1}:** {thumbnail.strip()}")
        
        # ìŠ¤í¬ë¦½íŠ¸ ì„¹ì…˜
        st.markdown("### ğŸ“ ìŠ¤í¬ë¦½íŠ¸")
        if hasattr(st.session_state, 'script'):
            st.markdown(st.session_state.script)
        
        # ì›ë³¸ í…ìŠ¤íŠ¸ (ì ‘ì„ ìˆ˜ ìˆê²Œ)
        with st.expander("ì›ë³¸ ìƒì„± í…ìŠ¤íŠ¸ ë³´ê¸°", expanded=False):
            if hasattr(st.session_state, 'generated_content'):
                st.text(st.session_state.generated_content)
